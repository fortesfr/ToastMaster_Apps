{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TM_Neurotic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5L4c2y9rB2UXqw/pNSkMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fortesfr/ToastMaster_Apps/blob/main/TM_Neurotic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Youtube Transcript Function"
      ],
      "metadata": {
        "id": "M5BAZhXK973A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itJKH4RnC7mE",
        "outputId": "13f8950e-3da6-4e58-e9dd-70f2d75031c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.4.3-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from youtube_transcript_api) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->youtube_transcript_api) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->youtube_transcript_api) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->youtube_transcript_api) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->youtube_transcript_api) (2.10)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api.formatters import JSONFormatter\n",
        "\n",
        "# Must be a single transcript.\n",
        "transcript = YouTubeTranscriptApi.get_transcript(\"GVsUOuSjvcg\")\n",
        "\n",
        "formatter = JSONFormatter()\n",
        "\n",
        "# .format_transcript(transcript) turns the transcript into a JSON string.\n",
        "json_formatted = formatter.format_transcript(transcript)\n",
        "\n",
        "\n",
        "# Now we can write it out to a file.\n",
        "with open('your_filename.json', 'w', encoding='utf-8') as json_file:\n",
        "    json_file.write(json_formatted)\n",
        "\n",
        "# Now should have a new JSON file that you can easily read back into Python"
      ],
      "metadata": {
        "id": "I6LXJF7S96uY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_formatted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "M_wRJ-A0D3Bc",
        "outputId": "6ad6d660-694c-41e0-f29b-f7d32be11599"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[{\"text\": \"- For hundreds of years,\", \"start\": 0.0, \"duration\": 1.35}, {\"text\": \"analog computers were the most\\\\npowerful computers on Earth,\", \"start\": 1.35, \"duration\": 3.75}, {\"text\": \"predicting eclipses, tides,\\\\nand guiding anti-aircraft guns.\", \"start\": 5.1, \"duration\": 4.62}, {\"text\": \"Then, with the advent of\\\\nsolid-state transistors,\", \"start\": 9.72, \"duration\": 2.93}, {\"text\": \"digital computers took off.\", \"start\": 12.65, \"duration\": 1.85}, {\"text\": \"Now, virtually every\\\\ncomputer we use is digital.\", \"start\": 14.5, \"duration\": 3.58}, {\"text\": \"But today, a perfect storm of\\\\nfactors is setting the scene\", \"start\": 18.08, \"duration\": 3.65}, {\"text\": \"for a resurgence of analog technology.\", \"start\": 21.73, \"duration\": 3.17}, {\"text\": \"This is an analog computer,\", \"start\": 24.9, \"duration\": 2.63}, {\"text\": \"and by connecting these\\\\nwires in particular ways,\", \"start\": 27.53, \"duration\": 2.9}, {\"text\": \"I can program it to solve a whole range\", \"start\": 30.43, \"duration\": 2.24}, {\"text\": \"of differential equations.\", \"start\": 32.67, \"duration\": 2.2}, {\"text\": \"For example, this setup\\\\nallows me to simulate\", \"start\": 34.87, \"duration\": 2.87}, {\"text\": \"a damped mass oscillating on a spring.\", \"start\": 37.74, \"duration\": 3.06}, {\"text\": \"So on the oscilloscope, you\\\\ncan actually see the position\", \"start\": 40.8, \"duration\": 2.92}, {\"text\": \"of the mass over time.\", \"start\": 43.72, \"duration\": 2.03}, {\"text\": \"And I can vary the damping,\", \"start\": 45.75, \"duration\": 3.19}, {\"text\": \"or the spring constant,\", \"start\": 48.94, \"duration\": 2.96}, {\"text\": \"or the mass, and we can\\\\nsee how the amplitude\", \"start\": 51.9, \"duration\": 2.84}, {\"text\": \"and duration of the oscillations change.\", \"start\": 54.74, \"duration\": 3.0}, {\"text\": \"Now what makes this an analog computer\", \"start\": 57.74, \"duration\": 2.32}, {\"text\": \"is that there are no\\\\nzeros and ones in here.\", \"start\": 60.06, \"duration\": 3.38}, {\"text\": \"Instead, there\\'s actually\\\\na voltage that oscillates\", \"start\": 63.44, \"duration\": 3.37}, {\"text\": \"up and down exactly\\\\nlike a mass on a spring.\", \"start\": 66.81, \"duration\": 3.45}, {\"text\": \"The electrical circuitry is an analog\", \"start\": 70.26, \"duration\": 2.51}, {\"text\": \"for the physical problem,\", \"start\": 72.77, \"duration\": 1.56}, {\"text\": \"it just takes place much faster.\", \"start\": 74.33, \"duration\": 2.33}, {\"text\": \"Now, if I change the\\\\nelectrical connections,\", \"start\": 76.66, \"duration\": 2.46}, {\"text\": \"I can program this computer\", \"start\": 79.12, \"duration\": 1.18}, {\"text\": \"to solve other differential equations,\", \"start\": 80.3, \"duration\": 1.97}, {\"text\": \"like the Lorenz system,\", \"start\": 82.27, \"duration\": 1.74}, {\"text\": \"which is a basic model of\\\\nconvection in the atmosphere.\", \"start\": 84.01, \"duration\": 3.28}, {\"text\": \"Now the Lorenz system is\\\\nfamous because it was one\", \"start\": 87.29, \"duration\": 2.17}, {\"text\": \"of the first discovered examples of chaos.\", \"start\": 89.46, \"duration\": 2.81}, {\"text\": \"And here, you can see the Lorenz attractor\", \"start\": 92.27, \"duration\": 3.25}, {\"text\": \"with its beautiful butterfly shape.\", \"start\": 95.52, \"duration\": 2.88}, {\"text\": \"And on this analog computer,\", \"start\": 98.4, \"duration\": 1.5}, {\"text\": \"I can change the parameters\", \"start\": 99.9, \"duration\": 2.46}, {\"text\": \"and see their effects in real time.\", \"start\": 102.36, \"duration\": 3.203}, {\"text\": \"So these examples illustrate some\", \"start\": 106.41, \"duration\": 1.57}, {\"text\": \"of the advantages of analog computers.\", \"start\": 107.98, \"duration\": 2.67}, {\"text\": \"They are incredibly\\\\npowerful computing devices,\", \"start\": 110.65, \"duration\": 2.61}, {\"text\": \"and they can complete a\\\\nlot of computations fast.\", \"start\": 113.26, \"duration\": 3.32}, {\"text\": \"Plus, they don\\'t take much power to do it.\", \"start\": 116.58, \"duration\": 2.553}, {\"text\": \"With a digital computer,\", \"start\": 121.52, \"duration\": 1.38}, {\"text\": \"if you wanna add two eight-bit numbers,\", \"start\": 122.9, \"duration\": 2.7}, {\"text\": \"you need around 50 transistors,\", \"start\": 125.6, \"duration\": 2.52}, {\"text\": \"whereas with an analog computer,\", \"start\": 128.12, \"duration\": 1.64}, {\"text\": \"you can add two currents,\", \"start\": 129.76, \"duration\": 2.48}, {\"text\": \"just by connecting two wires.\", \"start\": 132.24, \"duration\": 3.52}, {\"text\": \"With a digital computer\\\\nto multiply two numbers,\", \"start\": 135.76, \"duration\": 2.62}, {\"text\": \"you need on the order of 1,000 transistors\", \"start\": 138.38, \"duration\": 2.59}, {\"text\": \"all switching zeros and ones,\", \"start\": 140.97, \"duration\": 2.63}, {\"text\": \"whereas with an analog computer,\", \"start\": 143.6, \"duration\": 1.36}, {\"text\": \"you can pass a current through a resistor,\", \"start\": 144.96, \"duration\": 3.52}, {\"text\": \"and then the voltage across this resistor\", \"start\": 148.48, \"duration\": 3.37}, {\"text\": \"will be I times R.\", \"start\": 151.85, \"duration\": 2.44}, {\"text\": \"So effectively,\", \"start\": 154.29, \"duration\": 1.41}, {\"text\": \"you have multiplied two numbers together.\", \"start\": 155.7, \"duration\": 3.183}, {\"text\": \"But analog computers also\\\\nhave their drawbacks.\", \"start\": 160.01, \"duration\": 2.92}, {\"text\": \"For one thing,\", \"start\": 162.93, \"duration\": 0.833}, {\"text\": \"they are not general-purpose\\\\ncomputing devices.\", \"start\": 163.763, \"duration\": 2.667}, {\"text\": \"I mean, you\\'re not gonna run\\\\nMicrosoft Word on this thing.\", \"start\": 166.43, \"duration\": 3.0}, {\"text\": \"And also, since the inputs\\\\nand outputs are continuous,\", \"start\": 169.43, \"duration\": 3.56}, {\"text\": \"I can\\'t input exact values.\", \"start\": 172.99, \"duration\": 2.93}, {\"text\": \"So if I try to repeat\\\\nthe same calculation,\", \"start\": 175.92, \"duration\": 3.06}, {\"text\": \"I\\'m never going to get\\\\nthe exact same answer.\", \"start\": 178.98, \"duration\": 2.89}, {\"text\": \"Plus, think about\\\\nmanufacturing analog computers.\", \"start\": 181.87, \"duration\": 2.79}, {\"text\": \"There\\'s always gonna be some variation\", \"start\": 184.66, \"duration\": 1.64}, {\"text\": \"in the exact value of components,\", \"start\": 186.3, \"duration\": 1.9}, {\"text\": \"like resistors or capacitors.\", \"start\": 188.2, \"duration\": 2.17}, {\"text\": \"So as a general rule of thumb,\", \"start\": 190.37, \"duration\": 1.89}, {\"text\": \"you can expect about a 1% error.\", \"start\": 192.26, \"duration\": 3.28}, {\"text\": \"So when you think of analog computers,\", \"start\": 195.54, \"duration\": 1.8}, {\"text\": \"you can think powerful,\\\\nfast, and energy-efficient,\", \"start\": 197.34, \"duration\": 3.48}, {\"text\": \"but also single-purpose,\\\\nnon-repeatable, and inexact.\", \"start\": 200.82, \"duration\": 4.91}, {\"text\": \"And if those sound like deal-breakers,\", \"start\": 205.73, \"duration\": 2.41}, {\"text\": \"it\\'s because they probably are.\", \"start\": 208.14, \"duration\": 1.87}, {\"text\": \"I think these are the major reasons\", \"start\": 210.01, \"duration\": 1.84}, {\"text\": \"why analog computers fell out of favor\", \"start\": 211.85, \"duration\": 1.76}, {\"text\": \"as soon as digital\\\\ncomputers became viable.\", \"start\": 213.61, \"duration\": 3.29}, {\"text\": \"Now, here\\'s why analog computers\\\\nmay be making a comeback.\", \"start\": 216.9, \"duration\": 4.418}, {\"text\": \"(computers beeping)\", \"start\": 221.318, \"duration\": 2.482}, {\"text\": \"It all starts with\\\\nartificial intelligence.\", \"start\": 223.8, \"duration\": 2.7}, {\"text\": \"- [Narrator] A machine\\\\nhas been programmed to see\", \"start\": 226.5, \"duration\": 2.21}, {\"text\": \"and to move objects.\", \"start\": 228.71, \"duration\": 1.333}, {\"text\": \"- AI isn\\'t new.\", \"start\": 231.33, \"duration\": 1.61}, {\"text\": \"The term was coined back in 1956.\", \"start\": 232.94, \"duration\": 2.75}, {\"text\": \"In 1958, Cornell University psychologist,\", \"start\": 235.69, \"duration\": 3.07}, {\"text\": \"Frank Rosenblatt, built the perceptron,\", \"start\": 238.76, \"duration\": 2.53}, {\"text\": \"designed to mimic how\\\\nneurons fire in our brains.\", \"start\": 241.29, \"duration\": 3.86}, {\"text\": \"So here\\'s a basic model of how\\\\nneurons in our brains work.\", \"start\": 245.15, \"duration\": 3.78}, {\"text\": \"An individual neuron\\\\ncan either fire or not,\", \"start\": 248.93, \"duration\": 3.23}, {\"text\": \"so its level of activation\\\\ncan be represented\", \"start\": 252.16, \"duration\": 2.22}, {\"text\": \"as a one or a zero.\", \"start\": 254.38, \"duration\": 2.1}, {\"text\": \"The input to one neuron\", \"start\": 256.48, \"duration\": 1.89}, {\"text\": \"is the output from a bunch other neurons,\", \"start\": 258.37, \"duration\": 2.76}, {\"text\": \"but the strength of these connections\", \"start\": 261.13, \"duration\": 1.69}, {\"text\": \"between neurons varies,\", \"start\": 262.82, \"duration\": 1.59}, {\"text\": \"so each one can be given\\\\na different weight.\", \"start\": 264.41, \"duration\": 3.01}, {\"text\": \"Some connections are excitatory,\", \"start\": 267.42, \"duration\": 1.99}, {\"text\": \"so they have positive weights,\", \"start\": 269.41, \"duration\": 1.5}, {\"text\": \"while others are inhibitory,\", \"start\": 270.91, \"duration\": 1.93}, {\"text\": \"so they have negative weights.\", \"start\": 272.84, \"duration\": 1.71}, {\"text\": \"And the way to figure out\", \"start\": 274.55, \"duration\": 0.92}, {\"text\": \"whether a particular neuron fires,\", \"start\": 275.47, \"duration\": 2.2}, {\"text\": \"is to take the activation\\\\nof each input neuron\", \"start\": 277.67, \"duration\": 2.71}, {\"text\": \"and multiply by its weight,\", \"start\": 280.38, \"duration\": 2.22}, {\"text\": \"and then add these all together.\", \"start\": 282.6, \"duration\": 1.77}, {\"text\": \"If their sum is greater than\\\\nsome number called the bias,\", \"start\": 284.37, \"duration\": 3.12}, {\"text\": \"then the neuron fires,\", \"start\": 287.49, \"duration\": 1.56}, {\"text\": \"but if it\\'s less than that,\\\\nthe neuron doesn\\'t fire.\", \"start\": 289.05, \"duration\": 2.913}, {\"text\": \"As input, Rosenblatt\\'s\\\\nperceptron had 400 photocells\", \"start\": 293.46, \"duration\": 3.73}, {\"text\": \"arranged in a square grid,\", \"start\": 297.19, \"duration\": 1.89}, {\"text\": \"to capture a 20 by 20-pixel image.\", \"start\": 299.08, \"duration\": 3.08}, {\"text\": \"You can think of each\\\\npixel as an input neuron,\", \"start\": 302.16, \"duration\": 2.51}, {\"text\": \"with its activation being\\\\nthe brightness of the pixel.\", \"start\": 304.67, \"duration\": 3.11}, {\"text\": \"Although strictly speaking,\", \"start\": 307.78, \"duration\": 1.24}, {\"text\": \"the activation should\\\\nbe either zero or one,\", \"start\": 309.02, \"duration\": 2.89}, {\"text\": \"we can let it take any\\\\nvalue between zero and one.\", \"start\": 311.91, \"duration\": 4.05}, {\"text\": \"All of these neurons are connected\", \"start\": 315.96, \"duration\": 2.13}, {\"text\": \"to a single output neuron,\", \"start\": 318.09, \"duration\": 2.04}, {\"text\": \"each via its own adjustable weight.\", \"start\": 320.13, \"duration\": 3.01}, {\"text\": \"So to see if the output neuron will fire,\", \"start\": 323.14, \"duration\": 2.23}, {\"text\": \"you multiply the activation\\\\nof each neuron by its weight,\", \"start\": 325.37, \"duration\": 3.47}, {\"text\": \"and add them together.\", \"start\": 328.84, \"duration\": 1.6}, {\"text\": \"This is essentially a vector dot product.\", \"start\": 330.44, \"duration\": 2.82}, {\"text\": \"If the answer is larger than\\\\nthe bias, the neuron fires,\", \"start\": 333.26, \"duration\": 3.34}, {\"text\": \"and if not, it doesn\\'t.\", \"start\": 336.6, \"duration\": 2.29}, {\"text\": \"Now the goal of the perceptron\", \"start\": 338.89, \"duration\": 1.7}, {\"text\": \"was to reliably distinguish\\\\nbetween two images,\", \"start\": 340.59, \"duration\": 3.1}, {\"text\": \"like a rectangle and a circle.\", \"start\": 343.69, \"duration\": 2.28}, {\"text\": \"For example,\", \"start\": 345.97, \"duration\": 0.833}, {\"text\": \"the output neuron could always fire\", \"start\": 346.803, \"duration\": 1.797}, {\"text\": \"when presented with a circle,\", \"start\": 348.6, \"duration\": 1.35}, {\"text\": \"but never when presented with a rectangle.\", \"start\": 349.95, \"duration\": 2.98}, {\"text\": \"To achieve this, the\\\\nperception had to be trained,\", \"start\": 352.93, \"duration\": 2.96}, {\"text\": \"that is, shown a series\\\\nof different circles\", \"start\": 355.89, \"duration\": 2.52}, {\"text\": \"and rectangles, and have its\\\\nweights adjusted accordingly.\", \"start\": 358.41, \"duration\": 4.08}, {\"text\": \"We can visualize the weights as an image,\", \"start\": 362.49, \"duration\": 2.86}, {\"text\": \"since there\\'s a unique weight\\\\nfor each pixel of the image.\", \"start\": 365.35, \"duration\": 4.09}, {\"text\": \"Initially, Rosenblatt set\\\\nall the weights to zero.\", \"start\": 369.44, \"duration\": 3.03}, {\"text\": \"If the perceptron\\'s output is correct,\", \"start\": 372.47, \"duration\": 2.06}, {\"text\": \"for example, here it\\'s shown a rectangle\", \"start\": 374.53, \"duration\": 2.29}, {\"text\": \"and the output neuron doesn\\'t fire,\", \"start\": 376.82, \"duration\": 2.18}, {\"text\": \"no change is made to the weights.\", \"start\": 379.0, \"duration\": 2.26}, {\"text\": \"But if it\\'s wrong, then\\\\nthe weights are adjusted.\", \"start\": 381.26, \"duration\": 2.65}, {\"text\": \"The algorithm for updating the weights\", \"start\": 383.91, \"duration\": 2.01}, {\"text\": \"is remarkably simple.\", \"start\": 385.92, \"duration\": 1.72}, {\"text\": \"Here, the output neuron didn\\'t\\\\nfire when it was supposed to\", \"start\": 387.64, \"duration\": 3.09}, {\"text\": \"because it was shown a circle.\", \"start\": 390.73, \"duration\": 1.64}, {\"text\": \"So to modify the weights,\", \"start\": 392.37, \"duration\": 1.52}, {\"text\": \"you simply add the input\\\\nactivations to the weights.\", \"start\": 393.89, \"duration\": 4.32}, {\"text\": \"If the output neuron\\\\nfires when it shouldn\\'t,\", \"start\": 398.21, \"duration\": 2.33}, {\"text\": \"like here, when shown a rectangle,\", \"start\": 400.54, \"duration\": 2.35}, {\"text\": \"well, then you subtract\\\\nthe input activations\", \"start\": 402.89, \"duration\": 2.78}, {\"text\": \"from the weights, and you keep doing this\", \"start\": 405.67, \"duration\": 2.61}, {\"text\": \"until the perceptron correctly identifies\", \"start\": 408.28, \"duration\": 2.56}, {\"text\": \"all the training images.\", \"start\": 410.84, \"duration\": 1.79}, {\"text\": \"It was shown that this\\\\nalgorithm will always converge,\", \"start\": 412.63, \"duration\": 2.89}, {\"text\": \"so long as it\\'s possible\\\\nto map the two categories\", \"start\": 415.52, \"duration\": 2.66}, {\"text\": \"into distinct groups.\", \"start\": 418.18, \"duration\": 1.855}, {\"text\": \"(footsteps thumping)\", \"start\": 420.035, \"duration\": 2.205}, {\"text\": \"The perceptron was\\\\ncapable of distinguishing\", \"start\": 422.24, \"duration\": 2.72}, {\"text\": \"between different shapes,\\\\nlike rectangles and triangles,\", \"start\": 424.96, \"duration\": 2.94}, {\"text\": \"or between different letters.\", \"start\": 427.9, \"duration\": 1.32}, {\"text\": \"And according to Rosenblatt,\", \"start\": 429.22, \"duration\": 1.43}, {\"text\": \"it could even tell the\\\\ndifference between cats and dogs.\", \"start\": 430.65, \"duration\": 3.37}, {\"text\": \"He said the machine was capable\", \"start\": 434.02, \"duration\": 1.89}, {\"text\": \"of what amounts to original thought,\", \"start\": 435.91, \"duration\": 3.03}, {\"text\": \"and the media lapped it up.\", \"start\": 438.94, \"duration\": 1.94}, {\"text\": \"The \\\\\"New York Times\\\\\" called the perceptron\", \"start\": 440.88, \"duration\": 2.007}, {\"text\": \"\\\\\"the embryo of an electronic computer\", \"start\": 442.887, \"duration\": 2.393}, {\"text\": \"that the Navy expects will\\\\nbe able to walk, talk,\", \"start\": 445.28, \"duration\": 3.07}, {\"text\": \"see, write, reproduce itself,\", \"start\": 448.35, \"duration\": 2.54}, {\"text\": \"and be conscious of its existence.\\\\\"\", \"start\": 450.89, \"duration\": 2.757}, {\"text\": \"- [Narrator] After training\\\\non lots of examples,\", \"start\": 454.75, \"duration\": 2.2}, {\"text\": \"it\\'s given new faces it has never seen,\", \"start\": 456.95, \"duration\": 2.583}, {\"text\": \"and is able to successfully\\\\ndistinguish male from female.\", \"start\": 459.533, \"duration\": 3.947}, {\"text\": \"It has learned.\", \"start\": 463.48, \"duration\": 1.54}, {\"text\": \"- In reality, the perceptron\\\\nwas pretty limited\", \"start\": 465.02, \"duration\": 2.51}, {\"text\": \"in what it could do.\", \"start\": 467.53, \"duration\": 1.2}, {\"text\": \"It could not, in fact,\\\\ntell apart dogs from cats.\", \"start\": 468.73, \"duration\": 3.32}, {\"text\": \"This and other critiques were raised\", \"start\": 472.05, \"duration\": 1.9}, {\"text\": \"in a book by MIT giants,\\\\nMinsky and Papert, in 1969.\", \"start\": 473.95, \"duration\": 4.237}, {\"text\": \"And that led to a bust period\", \"start\": 478.187, \"duration\": 2.143}, {\"text\": \"for artificial neural\\\\nnetworks and AI in general.\", \"start\": 480.33, \"duration\": 3.2}, {\"text\": \"It\\'s known as the first AI winter.\", \"start\": 483.53, \"duration\": 3.19}, {\"text\": \"Rosenblatt did not survive this winter.\", \"start\": 486.72, \"duration\": 2.65}, {\"text\": \"He drowned while sailing in Chesapeake Bay\", \"start\": 489.37, \"duration\": 2.83}, {\"text\": \"on his 43rd birthday.\", \"start\": 492.2, \"duration\": 1.918}, {\"text\": \"(mellow upbeat music)\", \"start\": 494.118, \"duration\": 3.212}, {\"text\": \"- [Narrator] The NAV Lab\\\\nis a road-worthy truck,\", \"start\": 497.33, \"duration\": 2.33}, {\"text\": \"modified so that researchers or computers\", \"start\": 499.66, \"duration\": 2.63}, {\"text\": \"can control the vehicle\\\\nas occasion demands.\", \"start\": 502.29, \"duration\": 3.07}, {\"text\": \"- [Derek] In the 1980s,\\\\nthere was an AI resurgence\", \"start\": 505.36, \"duration\": 2.73}, {\"text\": \"when researchers at\\\\nCarnegie Mellon created one\", \"start\": 508.09, \"duration\": 2.0}, {\"text\": \"of the first self-driving cars.\", \"start\": 510.09, \"duration\": 2.38}, {\"text\": \"The vehicle was steered\", \"start\": 512.47, \"duration\": 1.39}, {\"text\": \"by an artificial neural\\\\nnetwork called ALVINN.\", \"start\": 513.86, \"duration\": 3.04}, {\"text\": \"It was similar to the perceptron,\", \"start\": 516.9, \"duration\": 1.05}, {\"text\": \"except it had a hidden\\\\nlayer of artificial neurons\", \"start\": 517.95, \"duration\": 3.13}, {\"text\": \"between the input and output.\", \"start\": 521.08, \"duration\": 2.22}, {\"text\": \"As input, ALVINN received\\\\n30 by 32-pixel images\", \"start\": 523.3, \"duration\": 3.76}, {\"text\": \"of the road ahead.\", \"start\": 527.06, \"duration\": 1.34}, {\"text\": \"Here, I\\'m showing them as 60 by 64 pixels.\", \"start\": 528.4, \"duration\": 3.2}, {\"text\": \"But each of these input\\\\nneurons was connected\", \"start\": 531.6, \"duration\": 2.42}, {\"text\": \"via an adjustable weight to a\\\\nhidden layer of four neurons.\", \"start\": 534.02, \"duration\": 3.93}, {\"text\": \"These were each connected\\\\nto 32 output neurons.\", \"start\": 537.95, \"duration\": 3.65}, {\"text\": \"So to go from one layer of\\\\nthe network to the next,\", \"start\": 541.6, \"duration\": 2.58}, {\"text\": \"you perform a matrix multiplication:\", \"start\": 544.18, \"duration\": 2.68}, {\"text\": \"the input activation times the weights.\", \"start\": 546.86, \"duration\": 3.26}, {\"text\": \"The output neuron with\\\\nthe greatest activation\", \"start\": 550.12, \"duration\": 2.46}, {\"text\": \"determines the steering angle.\", \"start\": 552.58, \"duration\": 1.903}, {\"text\": \"To train the neural net,\", \"start\": 555.54, \"duration\": 1.38}, {\"text\": \"a human drove the vehicle,\", \"start\": 556.92, \"duration\": 1.63}, {\"text\": \"providing the correct steering angle\", \"start\": 558.55, \"duration\": 2.35}, {\"text\": \"for a given input image.\", \"start\": 560.9, \"duration\": 1.82}, {\"text\": \"All the weights in the\\\\nneural network were adjusted\", \"start\": 562.72, \"duration\": 2.09}, {\"text\": \"through the training\", \"start\": 564.81, \"duration\": 0.833}, {\"text\": \"so that ALVINN\\'s output\\\\nbetter matched that\", \"start\": 565.643, \"duration\": 2.207}, {\"text\": \"of the human driver.\", \"start\": 567.85, \"duration\": 1.213}, {\"text\": \"The method for adjusting the weights\", \"start\": 570.27, \"duration\": 1.51}, {\"text\": \"is called backpropagation,\", \"start\": 571.78, \"duration\": 1.61}, {\"text\": \"which I won\\'t go into here,\", \"start\": 573.39, \"duration\": 1.54}, {\"text\": \"but Welch Labs has a great series on this,\", \"start\": 574.93, \"duration\": 2.42}, {\"text\": \"which I\\'ll link to in the description.\", \"start\": 577.35, \"duration\": 1.903}, {\"text\": \"Again, you can visualize the weights\", \"start\": 580.09, \"duration\": 1.81}, {\"text\": \"for the four hidden neurons as images.\", \"start\": 581.9, \"duration\": 2.6}, {\"text\": \"The weights are initially\\\\nset to be random,\", \"start\": 584.5, \"duration\": 2.22}, {\"text\": \"but as training progresses,\", \"start\": 586.72, \"duration\": 1.49}, {\"text\": \"the computer learns to pick\\\\nup on certain patterns.\", \"start\": 588.21, \"duration\": 3.55}, {\"text\": \"You can see the road markings\\\\nemerge in the weights.\", \"start\": 591.76, \"duration\": 3.13}, {\"text\": \"Simultaneously, the output\\\\nsteering angle coalesces\", \"start\": 594.89, \"duration\": 3.3}, {\"text\": \"onto the human steering angle.\", \"start\": 598.19, \"duration\": 2.43}, {\"text\": \"The computer drove the\\\\nvehicle at a top speed\", \"start\": 600.62, \"duration\": 2.46}, {\"text\": \"of around one or two kilometers per hour.\", \"start\": 603.08, \"duration\": 3.27}, {\"text\": \"It was limited by the speed\", \"start\": 606.35, \"duration\": 1.48}, {\"text\": \"at which the computer could\\\\nperform matrix multiplication.\", \"start\": 607.83, \"duration\": 2.933}, {\"text\": \"Despite these advances,\", \"start\": 612.25, \"duration\": 1.45}, {\"text\": \"artificial neural networks still struggled\", \"start\": 613.7, \"duration\": 2.11}, {\"text\": \"with seemingly simple tasks,\", \"start\": 615.81, \"duration\": 1.74}, {\"text\": \"like telling apart cats and dogs.\", \"start\": 617.55, \"duration\": 2.37}, {\"text\": \"And no one knew whether hardware\", \"start\": 619.92, \"duration\": 2.33}, {\"text\": \"or software was the weak link.\", \"start\": 622.25, \"duration\": 1.96}, {\"text\": \"I mean, did we have a good\\\\nmodel of intelligence,\", \"start\": 624.21, \"duration\": 2.35}, {\"text\": \"we just needed more computer power?\", \"start\": 626.56, \"duration\": 2.03}, {\"text\": \"Or, did we have the wrong idea\", \"start\": 628.59, \"duration\": 1.88}, {\"text\": \"about how to make intelligence\\\\nsystems altogether?\", \"start\": 630.47, \"duration\": 3.08}, {\"text\": \"So artificial intelligence\\\\nexperienced another lull\", \"start\": 633.55, \"duration\": 2.59}, {\"text\": \"in the 1990s.\", \"start\": 636.14, \"duration\": 2.01}, {\"text\": \"By the mid 2000s,\", \"start\": 638.15, \"duration\": 1.29}, {\"text\": \"most AI researchers were\\\\nfocused on improving algorithms.\", \"start\": 639.44, \"duration\": 3.81}, {\"text\": \"But one researcher, Fei-Fei Li,\", \"start\": 643.25, \"duration\": 2.62}, {\"text\": \"thought maybe there was\\\\na different problem.\", \"start\": 645.87, \"duration\": 2.39}, {\"text\": \"Maybe these artificial neural networks\", \"start\": 648.26, \"duration\": 2.09}, {\"text\": \"just needed more data to train on.\", \"start\": 650.35, \"duration\": 2.19}, {\"text\": \"So she planned to map out\\\\nthe entire world of objects.\", \"start\": 652.54, \"duration\": 3.63}, {\"text\": \"From 2006 to 2009, she created ImageNet,\", \"start\": 656.17, \"duration\": 3.05}, {\"text\": \"a database of 1.2 million\\\\nhuman-labeled images,\", \"start\": 659.22, \"duration\": 3.33}, {\"text\": \"which at the time,\", \"start\": 662.55, \"duration\": 0.833}, {\"text\": \"was the largest labeled image\\\\ndataset ever constructed.\", \"start\": 663.383, \"duration\": 2.947}, {\"text\": \"And from 2010 to 2017,\", \"start\": 666.33, \"duration\": 1.928}, {\"text\": \"ImageNet ran an annual contest:\", \"start\": 668.258, \"duration\": 2.142}, {\"text\": \"the ImageNet Large Scale\\\\nVisual Recognition Challenge,\", \"start\": 670.4, \"duration\": 3.34}, {\"text\": \"where software programs\\\\ncompeted to correctly detect\", \"start\": 673.74, \"duration\": 2.64}, {\"text\": \"and classify images.\", \"start\": 676.38, \"duration\": 1.59}, {\"text\": \"Images were classified into\\\\n1,000 different categories,\", \"start\": 677.97, \"duration\": 3.14}, {\"text\": \"including 90 different dog breeds.\", \"start\": 681.11, \"duration\": 2.41}, {\"text\": \"A neural network competing\\\\nin this competition\", \"start\": 683.52, \"duration\": 1.94}, {\"text\": \"would have an output\\\\nlayer of 1,000 neurons,\", \"start\": 685.46, \"duration\": 2.76}, {\"text\": \"each corresponding to a category of object\", \"start\": 688.22, \"duration\": 2.24}, {\"text\": \"that could appear in the image.\", \"start\": 690.46, \"duration\": 1.77}, {\"text\": \"If the image contains,\\\\nsay, a German shepherd,\", \"start\": 692.23, \"duration\": 2.27}, {\"text\": \"then the output neuron\\\\ncorresponding to German shepherd\", \"start\": 694.5, \"duration\": 2.93}, {\"text\": \"should have the highest activation.\", \"start\": 697.43, \"duration\": 2.34}, {\"text\": \"Unsurprisingly, it turned\\\\nout to be a tough challenge.\", \"start\": 699.77, \"duration\": 3.35}, {\"text\": \"One way to judge the performance of an AI\", \"start\": 703.12, \"duration\": 2.01}, {\"text\": \"is to see how often the five\\\\nhighest neuron activations\", \"start\": 705.13, \"duration\": 3.23}, {\"text\": \"do not include the correct category.\", \"start\": 708.36, \"duration\": 2.56}, {\"text\": \"This is the so-called top-5 error rate.\", \"start\": 710.92, \"duration\": 2.92}, {\"text\": \"In 2010, the best performer\\\\nhad a top-5 error rate\", \"start\": 713.84, \"duration\": 3.08}, {\"text\": \"of 28.2%, meaning that\\\\nnearly 1/3 of the time,\", \"start\": 716.92, \"duration\": 4.16}, {\"text\": \"the correct answer was not\\\\namong its top five guesses.\", \"start\": 721.08, \"duration\": 3.49}, {\"text\": \"In 2011, the error rate of\\\\nthe best performer was 25.8%,\", \"start\": 724.57, \"duration\": 4.7}, {\"text\": \"a substantial improvement.\", \"start\": 729.27, \"duration\": 2.09}, {\"text\": \"But the next year,\", \"start\": 731.36, \"duration\": 1.01}, {\"text\": \"an artificial neural network\", \"start\": 732.37, \"duration\": 1.25}, {\"text\": \"from the University of\\\\nToronto, called AlexNet,\", \"start\": 733.62, \"duration\": 2.6}, {\"text\": \"blew away the competition\", \"start\": 736.22, \"duration\": 1.65}, {\"text\": \"with a top-5 error rate of just 16.4%.\", \"start\": 737.87, \"duration\": 4.54}, {\"text\": \"What set AlexNet apart\\\\nwas its size and depth.\", \"start\": 742.41, \"duration\": 3.43}, {\"text\": \"The network consisted of eight layers,\", \"start\": 745.84, \"duration\": 1.88}, {\"text\": \"and in total, 500,000 neurons.\", \"start\": 747.72, \"duration\": 2.98}, {\"text\": \"To train AlexNet,\", \"start\": 750.7, \"duration\": 0.833}, {\"text\": \"60 million weights and biases\\\\nhad to be carefully adjusted\", \"start\": 751.533, \"duration\": 4.047}, {\"text\": \"using the training database.\", \"start\": 755.58, \"duration\": 1.92}, {\"text\": \"Because of all the big\\\\nmatrix multiplications,\", \"start\": 757.5, \"duration\": 2.54}, {\"text\": \"processing a single image\\\\nrequired 700 million\", \"start\": 760.04, \"duration\": 3.53}, {\"text\": \"individual math operations.\", \"start\": 763.57, \"duration\": 1.76}, {\"text\": \"So training was computationally intensive.\", \"start\": 765.33, \"duration\": 2.95}, {\"text\": \"The team managed it by\\\\npioneering the use of GPUs,\", \"start\": 768.28, \"duration\": 3.05}, {\"text\": \"graphical processing units,\", \"start\": 771.33, \"duration\": 1.58}, {\"text\": \"which are traditionally used\\\\nfor driving displays, screens.\", \"start\": 772.91, \"duration\": 3.42}, {\"text\": \"So they\\'re specialized for\\\\nfast parallel computations.\", \"start\": 776.33, \"duration\": 3.78}, {\"text\": \"The AlexNet paper\\\\ndescribing their research\", \"start\": 780.11, \"duration\": 2.41}, {\"text\": \"is a blockbuster.\", \"start\": 782.52, \"duration\": 1.74}, {\"text\": \"It\\'s now been cited over 100,000 times,\", \"start\": 784.26, \"duration\": 3.42}, {\"text\": \"and it identifies the\\\\nscale of the neural network\", \"start\": 787.68, \"duration\": 2.71}, {\"text\": \"as key to its success.\", \"start\": 790.39, \"duration\": 2.59}, {\"text\": \"It takes a lot of computation\\\\nto train and run the network,\", \"start\": 792.98, \"duration\": 3.18}, {\"text\": \"but the improvement in\\\\nperformance is worth it.\", \"start\": 796.16, \"duration\": 3.13}, {\"text\": \"With others following their lead,\", \"start\": 799.29, \"duration\": 1.45}, {\"text\": \"the top-5 error rate\", \"start\": 800.74, \"duration\": 1.27}, {\"text\": \"on the ImageNet competition plummeted\", \"start\": 802.01, \"duration\": 1.89}, {\"text\": \"in the years that followed,\\\\ndown to 3.6% in 2015.\", \"start\": 803.9, \"duration\": 4.31}, {\"text\": \"That is better than human performance.\", \"start\": 808.21, \"duration\": 2.95}, {\"text\": \"The neural network that achieved this\", \"start\": 811.16, \"duration\": 1.57}, {\"text\": \"had 100 layers of neurons.\", \"start\": 812.73, \"duration\": 2.3}, {\"text\": \"So the future is clear:\", \"start\": 815.03, \"duration\": 1.46}, {\"text\": \"We will see ever increasing demand\", \"start\": 816.49, \"duration\": 1.9}, {\"text\": \"for ever larger neural networks.\", \"start\": 818.39, \"duration\": 2.43}, {\"text\": \"And this is a problem for several reasons:\", \"start\": 820.82, \"duration\": 2.22}, {\"text\": \"One is energy consumption.\", \"start\": 823.04, \"duration\": 2.11}, {\"text\": \"Training a neural network\\\\nrequires an amount\", \"start\": 825.15, \"duration\": 1.91}, {\"text\": \"of electricity similar\\\\nto the yearly consumption\", \"start\": 827.06, \"duration\": 2.4}, {\"text\": \"of three households.\", \"start\": 829.46, \"duration\": 1.53}, {\"text\": \"Another issue is the so-called\\\\nVon Neumann Bottleneck.\", \"start\": 830.99, \"duration\": 3.11}, {\"text\": \"Virtually every modern digital computer\", \"start\": 834.1, \"duration\": 1.77}, {\"text\": \"stores data in memory,\", \"start\": 835.87, \"duration\": 1.33}, {\"text\": \"and then accesses it as needed over a bus.\", \"start\": 837.2, \"duration\": 3.16}, {\"text\": \"When performing the huge\\\\nmatrix multiplications required\", \"start\": 840.36, \"duration\": 2.48}, {\"text\": \"by deep neural networks,\", \"start\": 842.84, \"duration\": 1.39}, {\"text\": \"most of the time and energy goes\", \"start\": 844.23, \"duration\": 1.44}, {\"text\": \"into fetching those weight values rather\", \"start\": 845.67, \"duration\": 2.29}, {\"text\": \"than actually doing the computation.\", \"start\": 847.96, \"duration\": 2.53}, {\"text\": \"And finally, there are the\\\\nlimitations of Moore\\'s Law.\", \"start\": 850.49, \"duration\": 2.76}, {\"text\": \"For decades, the number of transistors\", \"start\": 853.25, \"duration\": 1.71}, {\"text\": \"on a chip has been doubling\\\\napproximately every two years,\", \"start\": 854.96, \"duration\": 3.23}, {\"text\": \"but now the size of a transistor\", \"start\": 858.19, \"duration\": 1.94}, {\"text\": \"is approaching the size of an atom.\", \"start\": 860.13, \"duration\": 1.78}, {\"text\": \"So there are some fundamental\\\\nphysical challenges\", \"start\": 861.91, \"duration\": 2.78}, {\"text\": \"to further miniaturization.\", \"start\": 864.69, \"duration\": 2.19}, {\"text\": \"So this is the perfect\\\\nstorm for analog computers.\", \"start\": 866.88, \"duration\": 3.39}, {\"text\": \"Digital computers are\\\\nreaching their limits.\", \"start\": 870.27, \"duration\": 2.37}, {\"text\": \"Meanwhile, neural networks\\\\nare exploding in popularity,\", \"start\": 872.64, \"duration\": 3.24}, {\"text\": \"and a lot of what they do boils down\", \"start\": 875.88, \"duration\": 2.12}, {\"text\": \"to a single task: matrix multiplication.\", \"start\": 878.0, \"duration\": 3.35}, {\"text\": \"Best of all, neural networks\\\\ndon\\'t need the precision\", \"start\": 881.35, \"duration\": 2.72}, {\"text\": \"of digital computers.\", \"start\": 884.07, \"duration\": 1.28}, {\"text\": \"Whether the neural net\\\\nis 96% or 98% confident\", \"start\": 885.35, \"duration\": 3.64}, {\"text\": \"the image contains a chicken,\", \"start\": 888.99, \"duration\": 1.42}, {\"text\": \"it doesn\\'t really matter,\\\\nit\\'s still a chicken.\", \"start\": 890.41, \"duration\": 2.4}, {\"text\": \"So slight variability in components\", \"start\": 892.81, \"duration\": 2.06}, {\"text\": \"or conditions can be tolerated.\", \"start\": 894.87, \"duration\": 2.502}, {\"text\": \"(upbeat rock music)\", \"start\": 897.372, \"duration\": 1.438}, {\"text\": \"I went to an analog\\\\ncomputing startup in Texas,\", \"start\": 898.81, \"duration\": 2.56}, {\"text\": \"called Mythic AI.\", \"start\": 901.37, \"duration\": 2.0}, {\"text\": \"Here, they\\'re creating analog\\\\nchips to run neural networks.\", \"start\": 903.37, \"duration\": 3.45}, {\"text\": \"And they demonstrated\\\\nseveral AI algorithms for me.\", \"start\": 906.82, \"duration\": 3.103}, {\"text\": \"- Oh, there you go.\", \"start\": 910.98, \"duration\": 0.833}, {\"text\": \"See, it\\'s getting you.\\\\n(Derek laughs)\", \"start\": 911.813, \"duration\": 1.477}, {\"text\": \"Yeah.\\\\n- That\\'s fascinating.\", \"start\": 913.29, \"duration\": 1.48}, {\"text\": \"- The biggest use case is\\\\naugmented in virtual reality.\", \"start\": 914.77, \"duration\": 2.86}, {\"text\": \"If your friend is in a different,\", \"start\": 917.63, \"duration\": 1.52}, {\"text\": \"they\\'re at their house\\\\nand you\\'re at your house,\", \"start\": 919.15, \"duration\": 1.56}, {\"text\": \"you can actually render each\\\\nother in the virtual world.\", \"start\": 920.71, \"duration\": 3.41}, {\"text\": \"So it needs to really\\\\nquickly capture your pose,\", \"start\": 924.12, \"duration\": 3.16}, {\"text\": \"and then render it in the VR world.\", \"start\": 927.28, \"duration\": 2.07}, {\"text\": \"- So, hang on, is this\\\\nfor the metaverse thing?\", \"start\": 929.35, \"duration\": 1.983}, {\"text\": \"- Yeah, this is a very\\\\nmetaverse application.\", \"start\": 931.333, \"duration\": 4.307}, {\"text\": \"This is depth estimation\\\\nfrom just a single webcam.\", \"start\": 935.64, \"duration\": 2.99}, {\"text\": \"It\\'s just taking this scene,\", \"start\": 938.63, \"duration\": 1.32}, {\"text\": \"and then it\\'s doing a heat map.\", \"start\": 939.95, \"duration\": 1.41}, {\"text\": \"So if it\\'s bright, it means it\\'s close.\", \"start\": 941.36, \"duration\": 2.39}, {\"text\": \"And if it\\'s far away, it makes it black.\", \"start\": 943.75, \"duration\": 2.23}, {\"text\": \"- [Derek] Now all these\\\\nalgorithms can be run\", \"start\": 945.98, \"duration\": 1.58}, {\"text\": \"on digital computers,\", \"start\": 947.56, \"duration\": 1.29}, {\"text\": \"but here, the matrix multiplication\\\\nis actually taking place\", \"start\": 948.85, \"duration\": 3.4}, {\"text\": \"in the analog domain.\\\\n(light music)\", \"start\": 952.25, \"duration\": 2.17}, {\"text\": \"To make this possible,\", \"start\": 954.42, \"duration\": 1.38}, {\"text\": \"Mythic has repurposed\\\\ndigital flash storage cells.\", \"start\": 955.8, \"duration\": 3.69}, {\"text\": \"Normally these are used as memory\", \"start\": 959.49, \"duration\": 1.72}, {\"text\": \"to store either a one or a zero.\", \"start\": 961.21, \"duration\": 2.42}, {\"text\": \"If you apply a large positive\\\\nvoltage to the control gate,\", \"start\": 963.63, \"duration\": 3.83}, {\"text\": \"electrons tunnel up through\\\\nan insulating barrier\", \"start\": 967.46, \"duration\": 2.75}, {\"text\": \"and become trapped on the floating gate.\", \"start\": 970.21, \"duration\": 2.23}, {\"text\": \"Remove the voltage,\", \"start\": 972.44, \"duration\": 1.13}, {\"text\": \"and the electrons can\\\\nremain on the floating gate\", \"start\": 973.57, \"duration\": 1.87}, {\"text\": \"for decades, preventing the\\\\ncell from conducting current.\", \"start\": 975.44, \"duration\": 3.169}, {\"text\": \"And that\\'s how you can store\\\\neither a one or a zero.\", \"start\": 978.609, \"duration\": 2.711}, {\"text\": \"You can read out the stored value\", \"start\": 981.32, \"duration\": 1.64}, {\"text\": \"by applying a small voltage.\", \"start\": 982.96, \"duration\": 2.1}, {\"text\": \"If there are electrons\\\\non the floating gate,\", \"start\": 985.06, \"duration\": 1.91}, {\"text\": \"no current flows, so that\\'s a zero.\", \"start\": 986.97, \"duration\": 2.61}, {\"text\": \"If there aren\\'t electrons,\", \"start\": 989.58, \"duration\": 1.36}, {\"text\": \"then current does flow, and that\\'s a one.\", \"start\": 990.94, \"duration\": 2.98}, {\"text\": \"Now Mythic\\'s idea is to use these cells\", \"start\": 993.92, \"duration\": 2.11}, {\"text\": \"not as on/off switches,\\\\nbut as variable resistors.\", \"start\": 996.03, \"duration\": 3.97}, {\"text\": \"They do this by putting a\\\\nspecific number of electrons\", \"start\": 1000.0, \"duration\": 2.9}, {\"text\": \"on each floating gate,\\\\ninstead of all or nothing.\", \"start\": 1002.9, \"duration\": 2.77}, {\"text\": \"The greater the number of electrons,\", \"start\": 1005.67, \"duration\": 1.66}, {\"text\": \"the higher the resistance of the channel.\", \"start\": 1007.33, \"duration\": 2.48}, {\"text\": \"When you later apply a small voltage,\", \"start\": 1009.81, \"duration\": 2.19}, {\"text\": \"the current that flows\\\\nis equal to V over R.\", \"start\": 1012.0, \"duration\": 3.72}, {\"text\": \"But you can also think of this\\\\nas voltage times conductance,\", \"start\": 1015.72, \"duration\": 3.53}, {\"text\": \"where conductance is just\\\\nthe reciprocal of resistance.\", \"start\": 1019.25, \"duration\": 3.26}, {\"text\": \"So a single flash cell can be used\", \"start\": 1022.51, \"duration\": 1.96}, {\"text\": \"to multiply two values together,\\\\nvoltage times conductance.\", \"start\": 1024.47, \"duration\": 4.66}, {\"text\": \"So to use this to run an\\\\nartificial neural network,\", \"start\": 1029.13, \"duration\": 2.73}, {\"text\": \"well they first write all the\\\\nweights to the flash cells\", \"start\": 1031.86, \"duration\": 2.89}, {\"text\": \"as each cell\\'s conductance.\", \"start\": 1034.75, \"duration\": 2.12}, {\"text\": \"Then, they input the activation values\", \"start\": 1036.87, \"duration\": 2.4}, {\"text\": \"as the voltage on the cells.\", \"start\": 1039.27, \"duration\": 2.22}, {\"text\": \"And the resulting current is the product\", \"start\": 1041.49, \"duration\": 2.14}, {\"text\": \"of voltage times conductance,\", \"start\": 1043.63, \"duration\": 1.87}, {\"text\": \"which is activation times weight.\", \"start\": 1045.5, \"duration\": 2.8}, {\"text\": \"The cells are wired together in such a way\", \"start\": 1048.3, \"duration\": 2.56}, {\"text\": \"that the current from each\\\\nmultiplication adds together,\", \"start\": 1050.86, \"duration\": 3.14}, {\"text\": \"completing the matrix multiplication.\", \"start\": 1054.0, \"duration\": 2.607}, {\"text\": \"(light music)\", \"start\": 1056.607, \"duration\": 2.433}, {\"text\": \"- So this is our first product.\", \"start\": 1059.04, \"duration\": 1.88}, {\"text\": \"This can do 25 trillion\\\\nmath operations per second.\", \"start\": 1060.92, \"duration\": 4.94}, {\"text\": \"- [Derek] 25 trillion.\", \"start\": 1065.86, \"duration\": 1.18}, {\"text\": \"- Yep, 25 trillion math\\\\noperations per second,\", \"start\": 1067.04, \"duration\": 2.36}, {\"text\": \"in this little chip here,\", \"start\": 1069.4, \"duration\": 1.14}, {\"text\": \"burning about three watts of power.\", \"start\": 1070.54, \"duration\": 2.08}, {\"text\": \"- [Derek] How does it\\\\ncompare to a digital chip?\", \"start\": 1072.62, \"duration\": 2.31}, {\"text\": \"- The newer digital\\\\nsystems can do anywhere\", \"start\": 1074.93, \"duration\": 2.97}, {\"text\": \"from 25 to 100 trillion\\\\noperations per second,\", \"start\": 1077.9, \"duration\": 2.78}, {\"text\": \"but they are big, thousand-dollar systems\", \"start\": 1080.68, \"duration\": 2.1}, {\"text\": \"that are spitting out 50\\\\nto 100 watts of power.\", \"start\": 1082.78, \"duration\": 3.81}, {\"text\": \"- [Derek] Obviously this isn\\'t\", \"start\": 1086.59, \"duration\": 1.09}, {\"text\": \"like an apples apples comparison, right?\", \"start\": 1087.68, \"duration\": 1.78}, {\"text\": \"- No, it\\'s not apples to apples.\", \"start\": 1089.46, \"duration\": 1.12}, {\"text\": \"I mean, training those algorithms,\", \"start\": 1090.58, \"duration\": 3.08}, {\"text\": \"you need big hardware like this.\", \"start\": 1093.66, \"duration\": 1.85}, {\"text\": \"You can just do all sorts\\\\nof stuff on the GPU,\", \"start\": 1095.51, \"duration\": 2.1}, {\"text\": \"but if you specifically\\\\nare doing AI workloads\", \"start\": 1097.61, \"duration\": 2.75}, {\"text\": \"and you wanna deploy \\'em,\\\\nyou could use this instead.\", \"start\": 1100.36, \"duration\": 2.36}, {\"text\": \"You can imagine them in security cameras,\", \"start\": 1102.72, \"duration\": 2.45}, {\"text\": \"autonomous systems,\", \"start\": 1105.17, \"duration\": 1.52}, {\"text\": \"inspection equipment for manufacturing.\", \"start\": 1106.69, \"duration\": 2.43}, {\"text\": \"Every time they make a Frito-Lay chip,\", \"start\": 1109.12, \"duration\": 1.76}, {\"text\": \"they inspect it with a camera,\", \"start\": 1110.88, \"duration\": 1.32}, {\"text\": \"and the bad Fritos get blown\\\\noff of the conveyor belt.\", \"start\": 1112.2, \"duration\": 3.97}, {\"text\": \"But they\\'re using artificial intelligence\", \"start\": 1116.17, \"duration\": 1.58}, {\"text\": \"to spot which Fritos are good and bad.\", \"start\": 1117.75, \"duration\": 2.66}, {\"text\": \"- Some have proposed\\\\nusing analog circuitry\", \"start\": 1120.41, \"duration\": 2.24}, {\"text\": \"in smart home speakers,\", \"start\": 1122.65, \"duration\": 1.27}, {\"text\": \"solely to listen for the wake\\\\nword, like Alexa or Siri.\", \"start\": 1123.92, \"duration\": 3.73}, {\"text\": \"They would use a lot less\\\\npower and be able to quickly\", \"start\": 1127.65, \"duration\": 2.29}, {\"text\": \"and reliably turn on the\\\\ndigital circuitry of the device.\", \"start\": 1129.94, \"duration\": 3.37}, {\"text\": \"But you still have to deal\\\\nwith the challenges of analog.\", \"start\": 1133.31, \"duration\": 3.11}, {\"text\": \"- So for one of the popular networks,\", \"start\": 1136.42, \"duration\": 1.7}, {\"text\": \"there would be 50 sequences\", \"start\": 1138.12, \"duration\": 2.62}, {\"text\": \"of matrix multiplies that you\\'re doing.\", \"start\": 1140.74, \"duration\": 1.93}, {\"text\": \"Now, if you did that entirely\\\\nin the analog domain,\", \"start\": 1142.67, \"duration\": 2.37}, {\"text\": \"by the time it gets to the output,\", \"start\": 1145.04, \"duration\": 1.3}, {\"text\": \"it\\'s just so distorted\", \"start\": 1146.34, \"duration\": 1.47}, {\"text\": \"that you don\\'t have any result at all.\", \"start\": 1147.81, \"duration\": 2.45}, {\"text\": \"So you convert it from the analog domain,\", \"start\": 1150.26, \"duration\": 1.87}, {\"text\": \"back to the digital domain,\", \"start\": 1152.13, \"duration\": 1.96}, {\"text\": \"send it to the next processing block,\", \"start\": 1154.09, \"duration\": 1.88}, {\"text\": \"and then you convert it into\\\\nthe analog domain again.\", \"start\": 1155.97, \"duration\": 2.39}, {\"text\": \"And that allows you to\\\\npreserve the signal.\", \"start\": 1158.36, \"duration\": 2.13}, {\"text\": \"- You know, when Rosenblatt\\\\nwas first setting\", \"start\": 1160.49, \"duration\": 2.15}, {\"text\": \"up his perceptron,\", \"start\": 1162.64, \"duration\": 1.11}, {\"text\": \"he used a digital IBM computer.\", \"start\": 1163.75, \"duration\": 2.95}, {\"text\": \"Finding it too slow,\", \"start\": 1166.7, \"duration\": 1.63}, {\"text\": \"he built a custom analog computer,\", \"start\": 1168.33, \"duration\": 2.51}, {\"text\": \"complete with variable resistors\", \"start\": 1170.84, \"duration\": 1.73}, {\"text\": \"and little motors to drive them.\", \"start\": 1172.57, \"duration\": 2.72}, {\"text\": \"Ultimately, his idea of neural networks\", \"start\": 1175.29, \"duration\": 2.52}, {\"text\": \"turned out to be right.\", \"start\": 1177.81, \"duration\": 1.59}, {\"text\": \"Maybe he was right about analog, too.\", \"start\": 1179.4, \"duration\": 2.973}, {\"text\": \"Now, I can\\'t say whether\\\\nanalog computers will take\", \"start\": 1183.25, \"duration\": 2.92}, {\"text\": \"off the way digital did last century,\", \"start\": 1186.17, \"duration\": 2.52}, {\"text\": \"but they do seem to be better suited\", \"start\": 1188.69, \"duration\": 2.67}, {\"text\": \"to a lot of the tasks\\\\nthat we want computers\", \"start\": 1191.36, \"duration\": 2.19}, {\"text\": \"to perform today,\", \"start\": 1193.55, \"duration\": 1.66}, {\"text\": \"which is a little bit funny\", \"start\": 1195.21, \"duration\": 1.03}, {\"text\": \"because I always thought of digital\", \"start\": 1196.24, \"duration\": 1.84}, {\"text\": \"as the optimal way of\\\\nprocessing information.\", \"start\": 1198.08, \"duration\": 3.45}, {\"text\": \"Everything from music to pictures,\", \"start\": 1201.53, \"duration\": 2.24}, {\"text\": \"to video has all gone\\\\ndigital in the last 50 years.\", \"start\": 1203.77, \"duration\": 4.09}, {\"text\": \"But maybe in a 100 years,\", \"start\": 1207.86, \"duration\": 1.81}, {\"text\": \"we will look back on digital,\", \"start\": 1209.67, \"duration\": 1.437}, {\"text\": \"not not as the end point\\\\nof information technology,\", \"start\": 1211.107, \"duration\": 3.953}, {\"text\": \"but as a starting point.\", \"start\": 1215.06, \"duration\": 2.26}, {\"text\": \"Our brains are digital\", \"start\": 1217.32, \"duration\": 1.75}, {\"text\": \"in that a neuron either\\\\nfires or it doesn\\'t,\", \"start\": 1219.07, \"duration\": 2.86}, {\"text\": \"but they\\'re also analog\", \"start\": 1221.93, \"duration\": 2.11}, {\"text\": \"in that thinking takes place\\\\neverywhere, all at once.\", \"start\": 1224.04, \"duration\": 4.18}, {\"text\": \"So maybe what we need\", \"start\": 1228.22, \"duration\": 1.85}, {\"text\": \"to achieve true artificial intelligence,\", \"start\": 1230.07, \"duration\": 2.42}, {\"text\": \"machines that think like\\\\nus, is the power of analog.\", \"start\": 1232.49, \"duration\": 4.644}, {\"text\": \"(gentle music)\", \"start\": 1237.134, \"duration\": 2.583}, {\"text\": \"Hey, I learned a lot\\\\nwhile making this video,\", \"start\": 1242.04, \"duration\": 2.27}, {\"text\": \"much of it by playing with\\\\nan actual analog computer.\", \"start\": 1244.31, \"duration\": 2.97}, {\"text\": \"You know, trying things out for yourself\", \"start\": 1247.28, \"duration\": 1.53}, {\"text\": \"is really the best way to learn,\", \"start\": 1248.81, \"duration\": 1.49}, {\"text\": \"and you can do that with this\\\\nvideo sponsor, Brilliant.\", \"start\": 1250.3, \"duration\": 3.17}, {\"text\": \"Brilliant is a website and app\", \"start\": 1253.47, \"duration\": 1.36}, {\"text\": \"that gets you thinking deeply\", \"start\": 1254.83, \"duration\": 1.23}, {\"text\": \"by engaging you in problem-solving.\", \"start\": 1256.06, \"duration\": 2.14}, {\"text\": \"They have a great course\\\\non neural networks,\", \"start\": 1258.2, \"duration\": 1.85}, {\"text\": \"where you can test how\\\\nit works for yourself.\", \"start\": 1260.05, \"duration\": 2.41}, {\"text\": \"It gives you an excellent intuition\", \"start\": 1262.46, \"duration\": 1.83}, {\"text\": \"about how neural networks can\\\\nrecognize numbers and shapes,\", \"start\": 1264.29, \"duration\": 3.1}, {\"text\": \"and it also allows you to\\\\nexperience the importance\", \"start\": 1267.39, \"duration\": 2.16}, {\"text\": \"of good training data and hidden layers\", \"start\": 1269.55, \"duration\": 2.3}, {\"text\": \"to understand why more sophisticated\", \"start\": 1271.85, \"duration\": 2.19}, {\"text\": \"neural networks work better.\", \"start\": 1274.04, \"duration\": 1.82}, {\"text\": \"What I love about Brilliant\", \"start\": 1275.86, \"duration\": 1.08}, {\"text\": \"is it tests your knowledge as you go.\", \"start\": 1276.94, \"duration\": 2.38}, {\"text\": \"The lessons are highly interactive,\", \"start\": 1279.32, \"duration\": 1.49}, {\"text\": \"and they get progressively\\\\nharder as you go on.\", \"start\": 1280.81, \"duration\": 2.65}, {\"text\": \"And if you get stuck, there\\\\nare always helpful hints.\", \"start\": 1283.46, \"duration\": 3.16}, {\"text\": \"For viewers of this video,\", \"start\": 1286.62, \"duration\": 1.15}, {\"text\": \"Brilliant is offering the first 200 people\", \"start\": 1287.77, \"duration\": 1.8}, {\"text\": \"20% off an annual premium subscription.\", \"start\": 1289.57, \"duration\": 2.53}, {\"text\": \"Just go to brilliant.org/veritasium.\", \"start\": 1292.1, \"duration\": 3.11}, {\"text\": \"I will put that link\\\\ndown in the description.\", \"start\": 1295.21, \"duration\": 2.22}, {\"text\": \"So I wanna thank Brilliant\\\\nfor supporting Veritasium,\", \"start\": 1297.43, \"duration\": 2.6}, {\"text\": \"and I wanna thank you for watching.\", \"start\": 1300.03, \"duration\": 1.75}]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Popular sites include Clipconverter, Free CC Converter Tool, Keepvid (also offers video download), and Way With Words. "
      ],
      "metadata": {
        "id": "HFX-hqV5AkEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicized text*\n",
        "\n",
        "* style-scope ytd-engagement-panel-section-list-renderer (Largest Container of Transcript)\n",
        "* style-scope ytd-transcript-renderer (Smallest Container before individual lines)"
      ],
      "metadata": {
        "id": "fjadzWsd-5X6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMHd_KbI9z9_"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}