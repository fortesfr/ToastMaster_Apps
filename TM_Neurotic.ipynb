{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fortesfr/ToastMaster_Apps/blob/main/TM_Neurotic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5BAZhXK973A"
      },
      "source": [
        "# Youtube Transcript Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itJKH4RnC7mE",
        "outputId": "13f8950e-3da6-4e58-e9dd-70f2d75031c9"
      },
      "outputs": [],
      "source": [
        "# !pip3 install youtube_transcript_api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "I6LXJF7S96uY"
      },
      "outputs": [],
      "source": [
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from youtube_transcript_api.formatters import JSONFormatter\n",
        "\n",
        "# Must be a single transcript.\n",
        "transcript = YouTubeTranscriptApi.get_transcript(\"GVsUOuSjvcg\")\n",
        "\n",
        "formatter = JSONFormatter()\n",
        "\n",
        "# .format_transcript(transcript) turns the transcript into a JSON string.\n",
        "json_formatted = formatter.format_transcript(transcript)\n",
        "\n",
        "\n",
        "# Now we can write it out to a file.\n",
        "with open('your_filename.json', 'w', encoding='utf-8') as json_file:\n",
        "    json_file.write(json_formatted)\n",
        "\n",
        "# Now should have a new JSON file that you can easily read back into Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "M_wRJ-A0D3Bc",
        "outputId": "6ad6d660-694c-41e0-f29b-f7d32be11599"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': '- For hundreds of years,', 'start': 0.0, 'duration': 1.35},\n",
              " {'text': 'analog computers were the most\\npowerful computers on Earth,',\n",
              "  'start': 1.35,\n",
              "  'duration': 3.75},\n",
              " {'text': 'predicting eclipses, tides,\\nand guiding anti-aircraft guns.',\n",
              "  'start': 5.1,\n",
              "  'duration': 4.62},\n",
              " {'text': 'Then, with the advent of\\nsolid-state transistors,',\n",
              "  'start': 9.72,\n",
              "  'duration': 2.93},\n",
              " {'text': 'digital computers took off.', 'start': 12.65, 'duration': 1.85},\n",
              " {'text': 'Now, virtually every\\ncomputer we use is digital.',\n",
              "  'start': 14.5,\n",
              "  'duration': 3.58},\n",
              " {'text': 'But today, a perfect storm of\\nfactors is setting the scene',\n",
              "  'start': 18.08,\n",
              "  'duration': 3.65},\n",
              " {'text': 'for a resurgence of analog technology.',\n",
              "  'start': 21.73,\n",
              "  'duration': 3.17},\n",
              " {'text': 'This is an analog computer,', 'start': 24.9, 'duration': 2.63},\n",
              " {'text': 'and by connecting these\\nwires in particular ways,',\n",
              "  'start': 27.53,\n",
              "  'duration': 2.9},\n",
              " {'text': 'I can program it to solve a whole range',\n",
              "  'start': 30.43,\n",
              "  'duration': 2.24},\n",
              " {'text': 'of differential equations.', 'start': 32.67, 'duration': 2.2},\n",
              " {'text': 'For example, this setup\\nallows me to simulate',\n",
              "  'start': 34.87,\n",
              "  'duration': 2.87},\n",
              " {'text': 'a damped mass oscillating on a spring.',\n",
              "  'start': 37.74,\n",
              "  'duration': 3.06},\n",
              " {'text': 'So on the oscilloscope, you\\ncan actually see the position',\n",
              "  'start': 40.8,\n",
              "  'duration': 2.92},\n",
              " {'text': 'of the mass over time.', 'start': 43.72, 'duration': 2.03},\n",
              " {'text': 'And I can vary the damping,', 'start': 45.75, 'duration': 3.19},\n",
              " {'text': 'or the spring constant,', 'start': 48.94, 'duration': 2.96},\n",
              " {'text': 'or the mass, and we can\\nsee how the amplitude',\n",
              "  'start': 51.9,\n",
              "  'duration': 2.84},\n",
              " {'text': 'and duration of the oscillations change.',\n",
              "  'start': 54.74,\n",
              "  'duration': 3.0},\n",
              " {'text': 'Now what makes this an analog computer',\n",
              "  'start': 57.74,\n",
              "  'duration': 2.32},\n",
              " {'text': 'is that there are no\\nzeros and ones in here.',\n",
              "  'start': 60.06,\n",
              "  'duration': 3.38},\n",
              " {'text': \"Instead, there's actually\\na voltage that oscillates\",\n",
              "  'start': 63.44,\n",
              "  'duration': 3.37},\n",
              " {'text': 'up and down exactly\\nlike a mass on a spring.',\n",
              "  'start': 66.81,\n",
              "  'duration': 3.45},\n",
              " {'text': 'The electrical circuitry is an analog',\n",
              "  'start': 70.26,\n",
              "  'duration': 2.51},\n",
              " {'text': 'for the physical problem,', 'start': 72.77, 'duration': 1.56},\n",
              " {'text': 'it just takes place much faster.',\n",
              "  'start': 74.33,\n",
              "  'duration': 2.33},\n",
              " {'text': 'Now, if I change the\\nelectrical connections,',\n",
              "  'start': 76.66,\n",
              "  'duration': 2.46},\n",
              " {'text': 'I can program this computer', 'start': 79.12, 'duration': 1.18},\n",
              " {'text': 'to solve other differential equations,',\n",
              "  'start': 80.3,\n",
              "  'duration': 1.97},\n",
              " {'text': 'like the Lorenz system,', 'start': 82.27, 'duration': 1.74},\n",
              " {'text': 'which is a basic model of\\nconvection in the atmosphere.',\n",
              "  'start': 84.01,\n",
              "  'duration': 3.28},\n",
              " {'text': 'Now the Lorenz system is\\nfamous because it was one',\n",
              "  'start': 87.29,\n",
              "  'duration': 2.17},\n",
              " {'text': 'of the first discovered examples of chaos.',\n",
              "  'start': 89.46,\n",
              "  'duration': 2.81},\n",
              " {'text': 'And here, you can see the Lorenz attractor',\n",
              "  'start': 92.27,\n",
              "  'duration': 3.25},\n",
              " {'text': 'with its beautiful butterfly shape.',\n",
              "  'start': 95.52,\n",
              "  'duration': 2.88},\n",
              " {'text': 'And on this analog computer,', 'start': 98.4, 'duration': 1.5},\n",
              " {'text': 'I can change the parameters', 'start': 99.9, 'duration': 2.46},\n",
              " {'text': 'and see their effects in real time.',\n",
              "  'start': 102.36,\n",
              "  'duration': 3.203},\n",
              " {'text': 'So these examples illustrate some',\n",
              "  'start': 106.41,\n",
              "  'duration': 1.57},\n",
              " {'text': 'of the advantages of analog computers.',\n",
              "  'start': 107.98,\n",
              "  'duration': 2.67},\n",
              " {'text': 'They are incredibly\\npowerful computing devices,',\n",
              "  'start': 110.65,\n",
              "  'duration': 2.61},\n",
              " {'text': 'and they can complete a\\nlot of computations fast.',\n",
              "  'start': 113.26,\n",
              "  'duration': 3.32},\n",
              " {'text': \"Plus, they don't take much power to do it.\",\n",
              "  'start': 116.58,\n",
              "  'duration': 2.553},\n",
              " {'text': 'With a digital computer,', 'start': 121.52, 'duration': 1.38},\n",
              " {'text': 'if you wanna add two eight-bit numbers,',\n",
              "  'start': 122.9,\n",
              "  'duration': 2.7},\n",
              " {'text': 'you need around 50 transistors,', 'start': 125.6, 'duration': 2.52},\n",
              " {'text': 'whereas with an analog computer,',\n",
              "  'start': 128.12,\n",
              "  'duration': 1.64},\n",
              " {'text': 'you can add two currents,', 'start': 129.76, 'duration': 2.48},\n",
              " {'text': 'just by connecting two wires.', 'start': 132.24, 'duration': 3.52},\n",
              " {'text': 'With a digital computer\\nto multiply two numbers,',\n",
              "  'start': 135.76,\n",
              "  'duration': 2.62},\n",
              " {'text': 'you need on the order of 1,000 transistors',\n",
              "  'start': 138.38,\n",
              "  'duration': 2.59},\n",
              " {'text': 'all switching zeros and ones,', 'start': 140.97, 'duration': 2.63},\n",
              " {'text': 'whereas with an analog computer,',\n",
              "  'start': 143.6,\n",
              "  'duration': 1.36},\n",
              " {'text': 'you can pass a current through a resistor,',\n",
              "  'start': 144.96,\n",
              "  'duration': 3.52},\n",
              " {'text': 'and then the voltage across this resistor',\n",
              "  'start': 148.48,\n",
              "  'duration': 3.37},\n",
              " {'text': 'will be I times R.', 'start': 151.85, 'duration': 2.44},\n",
              " {'text': 'So effectively,', 'start': 154.29, 'duration': 1.41},\n",
              " {'text': 'you have multiplied two numbers together.',\n",
              "  'start': 155.7,\n",
              "  'duration': 3.183},\n",
              " {'text': 'But analog computers also\\nhave their drawbacks.',\n",
              "  'start': 160.01,\n",
              "  'duration': 2.92},\n",
              " {'text': 'For one thing,', 'start': 162.93, 'duration': 0.833},\n",
              " {'text': 'they are not general-purpose\\ncomputing devices.',\n",
              "  'start': 163.763,\n",
              "  'duration': 2.667},\n",
              " {'text': \"I mean, you're not gonna run\\nMicrosoft Word on this thing.\",\n",
              "  'start': 166.43,\n",
              "  'duration': 3.0},\n",
              " {'text': 'And also, since the inputs\\nand outputs are continuous,',\n",
              "  'start': 169.43,\n",
              "  'duration': 3.56},\n",
              " {'text': \"I can't input exact values.\", 'start': 172.99, 'duration': 2.93},\n",
              " {'text': 'So if I try to repeat\\nthe same calculation,',\n",
              "  'start': 175.92,\n",
              "  'duration': 3.06},\n",
              " {'text': \"I'm never going to get\\nthe exact same answer.\",\n",
              "  'start': 178.98,\n",
              "  'duration': 2.89},\n",
              " {'text': 'Plus, think about\\nmanufacturing analog computers.',\n",
              "  'start': 181.87,\n",
              "  'duration': 2.79},\n",
              " {'text': \"There's always gonna be some variation\",\n",
              "  'start': 184.66,\n",
              "  'duration': 1.64},\n",
              " {'text': 'in the exact value of components,',\n",
              "  'start': 186.3,\n",
              "  'duration': 1.9},\n",
              " {'text': 'like resistors or capacitors.', 'start': 188.2, 'duration': 2.17},\n",
              " {'text': 'So as a general rule of thumb,', 'start': 190.37, 'duration': 1.89},\n",
              " {'text': 'you can expect about a 1% error.',\n",
              "  'start': 192.26,\n",
              "  'duration': 3.28},\n",
              " {'text': 'So when you think of analog computers,',\n",
              "  'start': 195.54,\n",
              "  'duration': 1.8},\n",
              " {'text': 'you can think powerful,\\nfast, and energy-efficient,',\n",
              "  'start': 197.34,\n",
              "  'duration': 3.48},\n",
              " {'text': 'but also single-purpose,\\nnon-repeatable, and inexact.',\n",
              "  'start': 200.82,\n",
              "  'duration': 4.91},\n",
              " {'text': 'And if those sound like deal-breakers,',\n",
              "  'start': 205.73,\n",
              "  'duration': 2.41},\n",
              " {'text': \"it's because they probably are.\",\n",
              "  'start': 208.14,\n",
              "  'duration': 1.87},\n",
              " {'text': 'I think these are the major reasons',\n",
              "  'start': 210.01,\n",
              "  'duration': 1.84},\n",
              " {'text': 'why analog computers fell out of favor',\n",
              "  'start': 211.85,\n",
              "  'duration': 1.76},\n",
              " {'text': 'as soon as digital\\ncomputers became viable.',\n",
              "  'start': 213.61,\n",
              "  'duration': 3.29},\n",
              " {'text': \"Now, here's why analog computers\\nmay be making a comeback.\",\n",
              "  'start': 216.9,\n",
              "  'duration': 4.418},\n",
              " {'text': '(computers beeping)', 'start': 221.318, 'duration': 2.482},\n",
              " {'text': 'It all starts with\\nartificial intelligence.',\n",
              "  'start': 223.8,\n",
              "  'duration': 2.7},\n",
              " {'text': '- [Narrator] A machine\\nhas been programmed to see',\n",
              "  'start': 226.5,\n",
              "  'duration': 2.21},\n",
              " {'text': 'and to move objects.', 'start': 228.71, 'duration': 1.333},\n",
              " {'text': \"- AI isn't new.\", 'start': 231.33, 'duration': 1.61},\n",
              " {'text': 'The term was coined back in 1956.',\n",
              "  'start': 232.94,\n",
              "  'duration': 2.75},\n",
              " {'text': 'In 1958, Cornell University psychologist,',\n",
              "  'start': 235.69,\n",
              "  'duration': 3.07},\n",
              " {'text': 'Frank Rosenblatt, built the perceptron,',\n",
              "  'start': 238.76,\n",
              "  'duration': 2.53},\n",
              " {'text': 'designed to mimic how\\nneurons fire in our brains.',\n",
              "  'start': 241.29,\n",
              "  'duration': 3.86},\n",
              " {'text': \"So here's a basic model of how\\nneurons in our brains work.\",\n",
              "  'start': 245.15,\n",
              "  'duration': 3.78},\n",
              " {'text': 'An individual neuron\\ncan either fire or not,',\n",
              "  'start': 248.93,\n",
              "  'duration': 3.23},\n",
              " {'text': 'so its level of activation\\ncan be represented',\n",
              "  'start': 252.16,\n",
              "  'duration': 2.22},\n",
              " {'text': 'as a one or a zero.', 'start': 254.38, 'duration': 2.1},\n",
              " {'text': 'The input to one neuron', 'start': 256.48, 'duration': 1.89},\n",
              " {'text': 'is the output from a bunch other neurons,',\n",
              "  'start': 258.37,\n",
              "  'duration': 2.76},\n",
              " {'text': 'but the strength of these connections',\n",
              "  'start': 261.13,\n",
              "  'duration': 1.69},\n",
              " {'text': 'between neurons varies,', 'start': 262.82, 'duration': 1.59},\n",
              " {'text': 'so each one can be given\\na different weight.',\n",
              "  'start': 264.41,\n",
              "  'duration': 3.01},\n",
              " {'text': 'Some connections are excitatory,',\n",
              "  'start': 267.42,\n",
              "  'duration': 1.99},\n",
              " {'text': 'so they have positive weights,', 'start': 269.41, 'duration': 1.5},\n",
              " {'text': 'while others are inhibitory,', 'start': 270.91, 'duration': 1.93},\n",
              " {'text': 'so they have negative weights.', 'start': 272.84, 'duration': 1.71},\n",
              " {'text': 'And the way to figure out', 'start': 274.55, 'duration': 0.92},\n",
              " {'text': 'whether a particular neuron fires,',\n",
              "  'start': 275.47,\n",
              "  'duration': 2.2},\n",
              " {'text': 'is to take the activation\\nof each input neuron',\n",
              "  'start': 277.67,\n",
              "  'duration': 2.71},\n",
              " {'text': 'and multiply by its weight,', 'start': 280.38, 'duration': 2.22},\n",
              " {'text': 'and then add these all together.',\n",
              "  'start': 282.6,\n",
              "  'duration': 1.77},\n",
              " {'text': 'If their sum is greater than\\nsome number called the bias,',\n",
              "  'start': 284.37,\n",
              "  'duration': 3.12},\n",
              " {'text': 'then the neuron fires,', 'start': 287.49, 'duration': 1.56},\n",
              " {'text': \"but if it's less than that,\\nthe neuron doesn't fire.\",\n",
              "  'start': 289.05,\n",
              "  'duration': 2.913},\n",
              " {'text': \"As input, Rosenblatt's\\nperceptron had 400 photocells\",\n",
              "  'start': 293.46,\n",
              "  'duration': 3.73},\n",
              " {'text': 'arranged in a square grid,', 'start': 297.19, 'duration': 1.89},\n",
              " {'text': 'to capture a 20 by 20-pixel image.',\n",
              "  'start': 299.08,\n",
              "  'duration': 3.08},\n",
              " {'text': 'You can think of each\\npixel as an input neuron,',\n",
              "  'start': 302.16,\n",
              "  'duration': 2.51},\n",
              " {'text': 'with its activation being\\nthe brightness of the pixel.',\n",
              "  'start': 304.67,\n",
              "  'duration': 3.11},\n",
              " {'text': 'Although strictly speaking,', 'start': 307.78, 'duration': 1.24},\n",
              " {'text': 'the activation should\\nbe either zero or one,',\n",
              "  'start': 309.02,\n",
              "  'duration': 2.89},\n",
              " {'text': 'we can let it take any\\nvalue between zero and one.',\n",
              "  'start': 311.91,\n",
              "  'duration': 4.05},\n",
              " {'text': 'All of these neurons are connected',\n",
              "  'start': 315.96,\n",
              "  'duration': 2.13},\n",
              " {'text': 'to a single output neuron,', 'start': 318.09, 'duration': 2.04},\n",
              " {'text': 'each via its own adjustable weight.',\n",
              "  'start': 320.13,\n",
              "  'duration': 3.01},\n",
              " {'text': 'So to see if the output neuron will fire,',\n",
              "  'start': 323.14,\n",
              "  'duration': 2.23},\n",
              " {'text': 'you multiply the activation\\nof each neuron by its weight,',\n",
              "  'start': 325.37,\n",
              "  'duration': 3.47},\n",
              " {'text': 'and add them together.', 'start': 328.84, 'duration': 1.6},\n",
              " {'text': 'This is essentially a vector dot product.',\n",
              "  'start': 330.44,\n",
              "  'duration': 2.82},\n",
              " {'text': 'If the answer is larger than\\nthe bias, the neuron fires,',\n",
              "  'start': 333.26,\n",
              "  'duration': 3.34},\n",
              " {'text': \"and if not, it doesn't.\", 'start': 336.6, 'duration': 2.29},\n",
              " {'text': 'Now the goal of the perceptron', 'start': 338.89, 'duration': 1.7},\n",
              " {'text': 'was to reliably distinguish\\nbetween two images,',\n",
              "  'start': 340.59,\n",
              "  'duration': 3.1},\n",
              " {'text': 'like a rectangle and a circle.', 'start': 343.69, 'duration': 2.28},\n",
              " {'text': 'For example,', 'start': 345.97, 'duration': 0.833},\n",
              " {'text': 'the output neuron could always fire',\n",
              "  'start': 346.803,\n",
              "  'duration': 1.797},\n",
              " {'text': 'when presented with a circle,', 'start': 348.6, 'duration': 1.35},\n",
              " {'text': 'but never when presented with a rectangle.',\n",
              "  'start': 349.95,\n",
              "  'duration': 2.98},\n",
              " {'text': 'To achieve this, the\\nperception had to be trained,',\n",
              "  'start': 352.93,\n",
              "  'duration': 2.96},\n",
              " {'text': 'that is, shown a series\\nof different circles',\n",
              "  'start': 355.89,\n",
              "  'duration': 2.52},\n",
              " {'text': 'and rectangles, and have its\\nweights adjusted accordingly.',\n",
              "  'start': 358.41,\n",
              "  'duration': 4.08},\n",
              " {'text': 'We can visualize the weights as an image,',\n",
              "  'start': 362.49,\n",
              "  'duration': 2.86},\n",
              " {'text': \"since there's a unique weight\\nfor each pixel of the image.\",\n",
              "  'start': 365.35,\n",
              "  'duration': 4.09},\n",
              " {'text': 'Initially, Rosenblatt set\\nall the weights to zero.',\n",
              "  'start': 369.44,\n",
              "  'duration': 3.03},\n",
              " {'text': \"If the perceptron's output is correct,\",\n",
              "  'start': 372.47,\n",
              "  'duration': 2.06},\n",
              " {'text': \"for example, here it's shown a rectangle\",\n",
              "  'start': 374.53,\n",
              "  'duration': 2.29},\n",
              " {'text': \"and the output neuron doesn't fire,\",\n",
              "  'start': 376.82,\n",
              "  'duration': 2.18},\n",
              " {'text': 'no change is made to the weights.',\n",
              "  'start': 379.0,\n",
              "  'duration': 2.26},\n",
              " {'text': \"But if it's wrong, then\\nthe weights are adjusted.\",\n",
              "  'start': 381.26,\n",
              "  'duration': 2.65},\n",
              " {'text': 'The algorithm for updating the weights',\n",
              "  'start': 383.91,\n",
              "  'duration': 2.01},\n",
              " {'text': 'is remarkably simple.', 'start': 385.92, 'duration': 1.72},\n",
              " {'text': \"Here, the output neuron didn't\\nfire when it was supposed to\",\n",
              "  'start': 387.64,\n",
              "  'duration': 3.09},\n",
              " {'text': 'because it was shown a circle.', 'start': 390.73, 'duration': 1.64},\n",
              " {'text': 'So to modify the weights,', 'start': 392.37, 'duration': 1.52},\n",
              " {'text': 'you simply add the input\\nactivations to the weights.',\n",
              "  'start': 393.89,\n",
              "  'duration': 4.32},\n",
              " {'text': \"If the output neuron\\nfires when it shouldn't,\",\n",
              "  'start': 398.21,\n",
              "  'duration': 2.33},\n",
              " {'text': 'like here, when shown a rectangle,',\n",
              "  'start': 400.54,\n",
              "  'duration': 2.35},\n",
              " {'text': 'well, then you subtract\\nthe input activations',\n",
              "  'start': 402.89,\n",
              "  'duration': 2.78},\n",
              " {'text': 'from the weights, and you keep doing this',\n",
              "  'start': 405.67,\n",
              "  'duration': 2.61},\n",
              " {'text': 'until the perceptron correctly identifies',\n",
              "  'start': 408.28,\n",
              "  'duration': 2.56},\n",
              " {'text': 'all the training images.', 'start': 410.84, 'duration': 1.79},\n",
              " {'text': 'It was shown that this\\nalgorithm will always converge,',\n",
              "  'start': 412.63,\n",
              "  'duration': 2.89},\n",
              " {'text': \"so long as it's possible\\nto map the two categories\",\n",
              "  'start': 415.52,\n",
              "  'duration': 2.66},\n",
              " {'text': 'into distinct groups.', 'start': 418.18, 'duration': 1.855},\n",
              " {'text': '(footsteps thumping)', 'start': 420.035, 'duration': 2.205},\n",
              " {'text': 'The perceptron was\\ncapable of distinguishing',\n",
              "  'start': 422.24,\n",
              "  'duration': 2.72},\n",
              " {'text': 'between different shapes,\\nlike rectangles and triangles,',\n",
              "  'start': 424.96,\n",
              "  'duration': 2.94},\n",
              " {'text': 'or between different letters.', 'start': 427.9, 'duration': 1.32},\n",
              " {'text': 'And according to Rosenblatt,', 'start': 429.22, 'duration': 1.43},\n",
              " {'text': 'it could even tell the\\ndifference between cats and dogs.',\n",
              "  'start': 430.65,\n",
              "  'duration': 3.37},\n",
              " {'text': 'He said the machine was capable',\n",
              "  'start': 434.02,\n",
              "  'duration': 1.89},\n",
              " {'text': 'of what amounts to original thought,',\n",
              "  'start': 435.91,\n",
              "  'duration': 3.03},\n",
              " {'text': 'and the media lapped it up.', 'start': 438.94, 'duration': 1.94},\n",
              " {'text': 'The \"New York Times\" called the perceptron',\n",
              "  'start': 440.88,\n",
              "  'duration': 2.007},\n",
              " {'text': '\"the embryo of an electronic computer',\n",
              "  'start': 442.887,\n",
              "  'duration': 2.393},\n",
              " {'text': 'that the Navy expects will\\nbe able to walk, talk,',\n",
              "  'start': 445.28,\n",
              "  'duration': 3.07},\n",
              " {'text': 'see, write, reproduce itself,', 'start': 448.35, 'duration': 2.54},\n",
              " {'text': 'and be conscious of its existence.\"',\n",
              "  'start': 450.89,\n",
              "  'duration': 2.757},\n",
              " {'text': '- [Narrator] After training\\non lots of examples,',\n",
              "  'start': 454.75,\n",
              "  'duration': 2.2},\n",
              " {'text': \"it's given new faces it has never seen,\",\n",
              "  'start': 456.95,\n",
              "  'duration': 2.583},\n",
              " {'text': 'and is able to successfully\\ndistinguish male from female.',\n",
              "  'start': 459.533,\n",
              "  'duration': 3.947},\n",
              " {'text': 'It has learned.', 'start': 463.48, 'duration': 1.54},\n",
              " {'text': '- In reality, the perceptron\\nwas pretty limited',\n",
              "  'start': 465.02,\n",
              "  'duration': 2.51},\n",
              " {'text': 'in what it could do.', 'start': 467.53, 'duration': 1.2},\n",
              " {'text': 'It could not, in fact,\\ntell apart dogs from cats.',\n",
              "  'start': 468.73,\n",
              "  'duration': 3.32},\n",
              " {'text': 'This and other critiques were raised',\n",
              "  'start': 472.05,\n",
              "  'duration': 1.9},\n",
              " {'text': 'in a book by MIT giants,\\nMinsky and Papert, in 1969.',\n",
              "  'start': 473.95,\n",
              "  'duration': 4.237},\n",
              " {'text': 'And that led to a bust period',\n",
              "  'start': 478.187,\n",
              "  'duration': 2.143},\n",
              " {'text': 'for artificial neural\\nnetworks and AI in general.',\n",
              "  'start': 480.33,\n",
              "  'duration': 3.2},\n",
              " {'text': \"It's known as the first AI winter.\",\n",
              "  'start': 483.53,\n",
              "  'duration': 3.19},\n",
              " {'text': 'Rosenblatt did not survive this winter.',\n",
              "  'start': 486.72,\n",
              "  'duration': 2.65},\n",
              " {'text': 'He drowned while sailing in Chesapeake Bay',\n",
              "  'start': 489.37,\n",
              "  'duration': 2.83},\n",
              " {'text': 'on his 43rd birthday.', 'start': 492.2, 'duration': 1.918},\n",
              " {'text': '(mellow upbeat music)', 'start': 494.118, 'duration': 3.212},\n",
              " {'text': '- [Narrator] The NAV Lab\\nis a road-worthy truck,',\n",
              "  'start': 497.33,\n",
              "  'duration': 2.33},\n",
              " {'text': 'modified so that researchers or computers',\n",
              "  'start': 499.66,\n",
              "  'duration': 2.63},\n",
              " {'text': 'can control the vehicle\\nas occasion demands.',\n",
              "  'start': 502.29,\n",
              "  'duration': 3.07},\n",
              " {'text': '- [Derek] In the 1980s,\\nthere was an AI resurgence',\n",
              "  'start': 505.36,\n",
              "  'duration': 2.73},\n",
              " {'text': 'when researchers at\\nCarnegie Mellon created one',\n",
              "  'start': 508.09,\n",
              "  'duration': 2.0},\n",
              " {'text': 'of the first self-driving cars.',\n",
              "  'start': 510.09,\n",
              "  'duration': 2.38},\n",
              " {'text': 'The vehicle was steered', 'start': 512.47, 'duration': 1.39},\n",
              " {'text': 'by an artificial neural\\nnetwork called ALVINN.',\n",
              "  'start': 513.86,\n",
              "  'duration': 3.04},\n",
              " {'text': 'It was similar to the perceptron,',\n",
              "  'start': 516.9,\n",
              "  'duration': 1.05},\n",
              " {'text': 'except it had a hidden\\nlayer of artificial neurons',\n",
              "  'start': 517.95,\n",
              "  'duration': 3.13},\n",
              " {'text': 'between the input and output.', 'start': 521.08, 'duration': 2.22},\n",
              " {'text': 'As input, ALVINN received\\n30 by 32-pixel images',\n",
              "  'start': 523.3,\n",
              "  'duration': 3.76},\n",
              " {'text': 'of the road ahead.', 'start': 527.06, 'duration': 1.34},\n",
              " {'text': \"Here, I'm showing them as 60 by 64 pixels.\",\n",
              "  'start': 528.4,\n",
              "  'duration': 3.2},\n",
              " {'text': 'But each of these input\\nneurons was connected',\n",
              "  'start': 531.6,\n",
              "  'duration': 2.42},\n",
              " {'text': 'via an adjustable weight to a\\nhidden layer of four neurons.',\n",
              "  'start': 534.02,\n",
              "  'duration': 3.93},\n",
              " {'text': 'These were each connected\\nto 32 output neurons.',\n",
              "  'start': 537.95,\n",
              "  'duration': 3.65},\n",
              " {'text': 'So to go from one layer of\\nthe network to the next,',\n",
              "  'start': 541.6,\n",
              "  'duration': 2.58},\n",
              " {'text': 'you perform a matrix multiplication:',\n",
              "  'start': 544.18,\n",
              "  'duration': 2.68},\n",
              " {'text': 'the input activation times the weights.',\n",
              "  'start': 546.86,\n",
              "  'duration': 3.26},\n",
              " {'text': 'The output neuron with\\nthe greatest activation',\n",
              "  'start': 550.12,\n",
              "  'duration': 2.46},\n",
              " {'text': 'determines the steering angle.',\n",
              "  'start': 552.58,\n",
              "  'duration': 1.903},\n",
              " {'text': 'To train the neural net,', 'start': 555.54, 'duration': 1.38},\n",
              " {'text': 'a human drove the vehicle,', 'start': 556.92, 'duration': 1.63},\n",
              " {'text': 'providing the correct steering angle',\n",
              "  'start': 558.55,\n",
              "  'duration': 2.35},\n",
              " {'text': 'for a given input image.', 'start': 560.9, 'duration': 1.82},\n",
              " {'text': 'All the weights in the\\nneural network were adjusted',\n",
              "  'start': 562.72,\n",
              "  'duration': 2.09},\n",
              " {'text': 'through the training', 'start': 564.81, 'duration': 0.833},\n",
              " {'text': \"so that ALVINN's output\\nbetter matched that\",\n",
              "  'start': 565.643,\n",
              "  'duration': 2.207},\n",
              " {'text': 'of the human driver.', 'start': 567.85, 'duration': 1.213},\n",
              " {'text': 'The method for adjusting the weights',\n",
              "  'start': 570.27,\n",
              "  'duration': 1.51},\n",
              " {'text': 'is called backpropagation,', 'start': 571.78, 'duration': 1.61},\n",
              " {'text': \"which I won't go into here,\", 'start': 573.39, 'duration': 1.54},\n",
              " {'text': 'but Welch Labs has a great series on this,',\n",
              "  'start': 574.93,\n",
              "  'duration': 2.42},\n",
              " {'text': \"which I'll link to in the description.\",\n",
              "  'start': 577.35,\n",
              "  'duration': 1.903},\n",
              " {'text': 'Again, you can visualize the weights',\n",
              "  'start': 580.09,\n",
              "  'duration': 1.81},\n",
              " {'text': 'for the four hidden neurons as images.',\n",
              "  'start': 581.9,\n",
              "  'duration': 2.6},\n",
              " {'text': 'The weights are initially\\nset to be random,',\n",
              "  'start': 584.5,\n",
              "  'duration': 2.22},\n",
              " {'text': 'but as training progresses,', 'start': 586.72, 'duration': 1.49},\n",
              " {'text': 'the computer learns to pick\\nup on certain patterns.',\n",
              "  'start': 588.21,\n",
              "  'duration': 3.55},\n",
              " {'text': 'You can see the road markings\\nemerge in the weights.',\n",
              "  'start': 591.76,\n",
              "  'duration': 3.13},\n",
              " {'text': 'Simultaneously, the output\\nsteering angle coalesces',\n",
              "  'start': 594.89,\n",
              "  'duration': 3.3},\n",
              " {'text': 'onto the human steering angle.', 'start': 598.19, 'duration': 2.43},\n",
              " {'text': 'The computer drove the\\nvehicle at a top speed',\n",
              "  'start': 600.62,\n",
              "  'duration': 2.46},\n",
              " {'text': 'of around one or two kilometers per hour.',\n",
              "  'start': 603.08,\n",
              "  'duration': 3.27},\n",
              " {'text': 'It was limited by the speed', 'start': 606.35, 'duration': 1.48},\n",
              " {'text': 'at which the computer could\\nperform matrix multiplication.',\n",
              "  'start': 607.83,\n",
              "  'duration': 2.933},\n",
              " {'text': 'Despite these advances,', 'start': 612.25, 'duration': 1.45},\n",
              " {'text': 'artificial neural networks still struggled',\n",
              "  'start': 613.7,\n",
              "  'duration': 2.11},\n",
              " {'text': 'with seemingly simple tasks,', 'start': 615.81, 'duration': 1.74},\n",
              " {'text': 'like telling apart cats and dogs.',\n",
              "  'start': 617.55,\n",
              "  'duration': 2.37},\n",
              " {'text': 'And no one knew whether hardware',\n",
              "  'start': 619.92,\n",
              "  'duration': 2.33},\n",
              " {'text': 'or software was the weak link.', 'start': 622.25, 'duration': 1.96},\n",
              " {'text': 'I mean, did we have a good\\nmodel of intelligence,',\n",
              "  'start': 624.21,\n",
              "  'duration': 2.35},\n",
              " {'text': 'we just needed more computer power?',\n",
              "  'start': 626.56,\n",
              "  'duration': 2.03},\n",
              " {'text': 'Or, did we have the wrong idea', 'start': 628.59, 'duration': 1.88},\n",
              " {'text': 'about how to make intelligence\\nsystems altogether?',\n",
              "  'start': 630.47,\n",
              "  'duration': 3.08},\n",
              " {'text': 'So artificial intelligence\\nexperienced another lull',\n",
              "  'start': 633.55,\n",
              "  'duration': 2.59},\n",
              " {'text': 'in the 1990s.', 'start': 636.14, 'duration': 2.01},\n",
              " {'text': 'By the mid 2000s,', 'start': 638.15, 'duration': 1.29},\n",
              " {'text': 'most AI researchers were\\nfocused on improving algorithms.',\n",
              "  'start': 639.44,\n",
              "  'duration': 3.81},\n",
              " {'text': 'But one researcher, Fei-Fei Li,',\n",
              "  'start': 643.25,\n",
              "  'duration': 2.62},\n",
              " {'text': 'thought maybe there was\\na different problem.',\n",
              "  'start': 645.87,\n",
              "  'duration': 2.39},\n",
              " {'text': 'Maybe these artificial neural networks',\n",
              "  'start': 648.26,\n",
              "  'duration': 2.09},\n",
              " {'text': 'just needed more data to train on.',\n",
              "  'start': 650.35,\n",
              "  'duration': 2.19},\n",
              " {'text': 'So she planned to map out\\nthe entire world of objects.',\n",
              "  'start': 652.54,\n",
              "  'duration': 3.63},\n",
              " {'text': 'From 2006 to 2009, she created ImageNet,',\n",
              "  'start': 656.17,\n",
              "  'duration': 3.05},\n",
              " {'text': 'a database of 1.2 million\\nhuman-labeled images,',\n",
              "  'start': 659.22,\n",
              "  'duration': 3.33},\n",
              " {'text': 'which at the time,', 'start': 662.55, 'duration': 0.833},\n",
              " {'text': 'was the largest labeled image\\ndataset ever constructed.',\n",
              "  'start': 663.383,\n",
              "  'duration': 2.947},\n",
              " {'text': 'And from 2010 to 2017,', 'start': 666.33, 'duration': 1.928},\n",
              " {'text': 'ImageNet ran an annual contest:',\n",
              "  'start': 668.258,\n",
              "  'duration': 2.142},\n",
              " {'text': 'the ImageNet Large Scale\\nVisual Recognition Challenge,',\n",
              "  'start': 670.4,\n",
              "  'duration': 3.34},\n",
              " {'text': 'where software programs\\ncompeted to correctly detect',\n",
              "  'start': 673.74,\n",
              "  'duration': 2.64},\n",
              " {'text': 'and classify images.', 'start': 676.38, 'duration': 1.59},\n",
              " {'text': 'Images were classified into\\n1,000 different categories,',\n",
              "  'start': 677.97,\n",
              "  'duration': 3.14},\n",
              " {'text': 'including 90 different dog breeds.',\n",
              "  'start': 681.11,\n",
              "  'duration': 2.41},\n",
              " {'text': 'A neural network competing\\nin this competition',\n",
              "  'start': 683.52,\n",
              "  'duration': 1.94},\n",
              " {'text': 'would have an output\\nlayer of 1,000 neurons,',\n",
              "  'start': 685.46,\n",
              "  'duration': 2.76},\n",
              " {'text': 'each corresponding to a category of object',\n",
              "  'start': 688.22,\n",
              "  'duration': 2.24},\n",
              " {'text': 'that could appear in the image.',\n",
              "  'start': 690.46,\n",
              "  'duration': 1.77},\n",
              " {'text': 'If the image contains,\\nsay, a German shepherd,',\n",
              "  'start': 692.23,\n",
              "  'duration': 2.27},\n",
              " {'text': 'then the output neuron\\ncorresponding to German shepherd',\n",
              "  'start': 694.5,\n",
              "  'duration': 2.93},\n",
              " {'text': 'should have the highest activation.',\n",
              "  'start': 697.43,\n",
              "  'duration': 2.34},\n",
              " {'text': 'Unsurprisingly, it turned\\nout to be a tough challenge.',\n",
              "  'start': 699.77,\n",
              "  'duration': 3.35},\n",
              " {'text': 'One way to judge the performance of an AI',\n",
              "  'start': 703.12,\n",
              "  'duration': 2.01},\n",
              " {'text': 'is to see how often the five\\nhighest neuron activations',\n",
              "  'start': 705.13,\n",
              "  'duration': 3.23},\n",
              " {'text': 'do not include the correct category.',\n",
              "  'start': 708.36,\n",
              "  'duration': 2.56},\n",
              " {'text': 'This is the so-called top-5 error rate.',\n",
              "  'start': 710.92,\n",
              "  'duration': 2.92},\n",
              " {'text': 'In 2010, the best performer\\nhad a top-5 error rate',\n",
              "  'start': 713.84,\n",
              "  'duration': 3.08},\n",
              " {'text': 'of 28.2%, meaning that\\nnearly 1/3 of the time,',\n",
              "  'start': 716.92,\n",
              "  'duration': 4.16},\n",
              " {'text': 'the correct answer was not\\namong its top five guesses.',\n",
              "  'start': 721.08,\n",
              "  'duration': 3.49},\n",
              " {'text': 'In 2011, the error rate of\\nthe best performer was 25.8%,',\n",
              "  'start': 724.57,\n",
              "  'duration': 4.7},\n",
              " {'text': 'a substantial improvement.', 'start': 729.27, 'duration': 2.09},\n",
              " {'text': 'But the next year,', 'start': 731.36, 'duration': 1.01},\n",
              " {'text': 'an artificial neural network', 'start': 732.37, 'duration': 1.25},\n",
              " {'text': 'from the University of\\nToronto, called AlexNet,',\n",
              "  'start': 733.62,\n",
              "  'duration': 2.6},\n",
              " {'text': 'blew away the competition', 'start': 736.22, 'duration': 1.65},\n",
              " {'text': 'with a top-5 error rate of just 16.4%.',\n",
              "  'start': 737.87,\n",
              "  'duration': 4.54},\n",
              " {'text': 'What set AlexNet apart\\nwas its size and depth.',\n",
              "  'start': 742.41,\n",
              "  'duration': 3.43},\n",
              " {'text': 'The network consisted of eight layers,',\n",
              "  'start': 745.84,\n",
              "  'duration': 1.88},\n",
              " {'text': 'and in total, 500,000 neurons.', 'start': 747.72, 'duration': 2.98},\n",
              " {'text': 'To train AlexNet,', 'start': 750.7, 'duration': 0.833},\n",
              " {'text': '60 million weights and biases\\nhad to be carefully adjusted',\n",
              "  'start': 751.533,\n",
              "  'duration': 4.047},\n",
              " {'text': 'using the training database.', 'start': 755.58, 'duration': 1.92},\n",
              " {'text': 'Because of all the big\\nmatrix multiplications,',\n",
              "  'start': 757.5,\n",
              "  'duration': 2.54},\n",
              " {'text': 'processing a single image\\nrequired 700 million',\n",
              "  'start': 760.04,\n",
              "  'duration': 3.53},\n",
              " {'text': 'individual math operations.', 'start': 763.57, 'duration': 1.76},\n",
              " {'text': 'So training was computationally intensive.',\n",
              "  'start': 765.33,\n",
              "  'duration': 2.95},\n",
              " {'text': 'The team managed it by\\npioneering the use of GPUs,',\n",
              "  'start': 768.28,\n",
              "  'duration': 3.05},\n",
              " {'text': 'graphical processing units,', 'start': 771.33, 'duration': 1.58},\n",
              " {'text': 'which are traditionally used\\nfor driving displays, screens.',\n",
              "  'start': 772.91,\n",
              "  'duration': 3.42},\n",
              " {'text': \"So they're specialized for\\nfast parallel computations.\",\n",
              "  'start': 776.33,\n",
              "  'duration': 3.78},\n",
              " {'text': 'The AlexNet paper\\ndescribing their research',\n",
              "  'start': 780.11,\n",
              "  'duration': 2.41},\n",
              " {'text': 'is a blockbuster.', 'start': 782.52, 'duration': 1.74},\n",
              " {'text': \"It's now been cited over 100,000 times,\",\n",
              "  'start': 784.26,\n",
              "  'duration': 3.42},\n",
              " {'text': 'and it identifies the\\nscale of the neural network',\n",
              "  'start': 787.68,\n",
              "  'duration': 2.71},\n",
              " {'text': 'as key to its success.', 'start': 790.39, 'duration': 2.59},\n",
              " {'text': 'It takes a lot of computation\\nto train and run the network,',\n",
              "  'start': 792.98,\n",
              "  'duration': 3.18},\n",
              " {'text': 'but the improvement in\\nperformance is worth it.',\n",
              "  'start': 796.16,\n",
              "  'duration': 3.13},\n",
              " {'text': 'With others following their lead,',\n",
              "  'start': 799.29,\n",
              "  'duration': 1.45},\n",
              " {'text': 'the top-5 error rate', 'start': 800.74, 'duration': 1.27},\n",
              " {'text': 'on the ImageNet competition plummeted',\n",
              "  'start': 802.01,\n",
              "  'duration': 1.89},\n",
              " {'text': 'in the years that followed,\\ndown to 3.6% in 2015.',\n",
              "  'start': 803.9,\n",
              "  'duration': 4.31},\n",
              " {'text': 'That is better than human performance.',\n",
              "  'start': 808.21,\n",
              "  'duration': 2.95},\n",
              " {'text': 'The neural network that achieved this',\n",
              "  'start': 811.16,\n",
              "  'duration': 1.57},\n",
              " {'text': 'had 100 layers of neurons.', 'start': 812.73, 'duration': 2.3},\n",
              " {'text': 'So the future is clear:', 'start': 815.03, 'duration': 1.46},\n",
              " {'text': 'We will see ever increasing demand',\n",
              "  'start': 816.49,\n",
              "  'duration': 1.9},\n",
              " {'text': 'for ever larger neural networks.',\n",
              "  'start': 818.39,\n",
              "  'duration': 2.43},\n",
              " {'text': 'And this is a problem for several reasons:',\n",
              "  'start': 820.82,\n",
              "  'duration': 2.22},\n",
              " {'text': 'One is energy consumption.', 'start': 823.04, 'duration': 2.11},\n",
              " {'text': 'Training a neural network\\nrequires an amount',\n",
              "  'start': 825.15,\n",
              "  'duration': 1.91},\n",
              " {'text': 'of electricity similar\\nto the yearly consumption',\n",
              "  'start': 827.06,\n",
              "  'duration': 2.4},\n",
              " {'text': 'of three households.', 'start': 829.46, 'duration': 1.53},\n",
              " {'text': 'Another issue is the so-called\\nVon Neumann Bottleneck.',\n",
              "  'start': 830.99,\n",
              "  'duration': 3.11},\n",
              " {'text': 'Virtually every modern digital computer',\n",
              "  'start': 834.1,\n",
              "  'duration': 1.77},\n",
              " {'text': 'stores data in memory,', 'start': 835.87, 'duration': 1.33},\n",
              " {'text': 'and then accesses it as needed over a bus.',\n",
              "  'start': 837.2,\n",
              "  'duration': 3.16},\n",
              " {'text': 'When performing the huge\\nmatrix multiplications required',\n",
              "  'start': 840.36,\n",
              "  'duration': 2.48},\n",
              " {'text': 'by deep neural networks,', 'start': 842.84, 'duration': 1.39},\n",
              " {'text': 'most of the time and energy goes',\n",
              "  'start': 844.23,\n",
              "  'duration': 1.44},\n",
              " {'text': 'into fetching those weight values rather',\n",
              "  'start': 845.67,\n",
              "  'duration': 2.29},\n",
              " {'text': 'than actually doing the computation.',\n",
              "  'start': 847.96,\n",
              "  'duration': 2.53},\n",
              " {'text': \"And finally, there are the\\nlimitations of Moore's Law.\",\n",
              "  'start': 850.49,\n",
              "  'duration': 2.76},\n",
              " {'text': 'For decades, the number of transistors',\n",
              "  'start': 853.25,\n",
              "  'duration': 1.71},\n",
              " {'text': 'on a chip has been doubling\\napproximately every two years,',\n",
              "  'start': 854.96,\n",
              "  'duration': 3.23},\n",
              " {'text': 'but now the size of a transistor',\n",
              "  'start': 858.19,\n",
              "  'duration': 1.94},\n",
              " {'text': 'is approaching the size of an atom.',\n",
              "  'start': 860.13,\n",
              "  'duration': 1.78},\n",
              " {'text': 'So there are some fundamental\\nphysical challenges',\n",
              "  'start': 861.91,\n",
              "  'duration': 2.78},\n",
              " {'text': 'to further miniaturization.', 'start': 864.69, 'duration': 2.19},\n",
              " {'text': 'So this is the perfect\\nstorm for analog computers.',\n",
              "  'start': 866.88,\n",
              "  'duration': 3.39},\n",
              " {'text': 'Digital computers are\\nreaching their limits.',\n",
              "  'start': 870.27,\n",
              "  'duration': 2.37},\n",
              " {'text': 'Meanwhile, neural networks\\nare exploding in popularity,',\n",
              "  'start': 872.64,\n",
              "  'duration': 3.24},\n",
              " {'text': 'and a lot of what they do boils down',\n",
              "  'start': 875.88,\n",
              "  'duration': 2.12},\n",
              " {'text': 'to a single task: matrix multiplication.',\n",
              "  'start': 878.0,\n",
              "  'duration': 3.35},\n",
              " {'text': \"Best of all, neural networks\\ndon't need the precision\",\n",
              "  'start': 881.35,\n",
              "  'duration': 2.72},\n",
              " {'text': 'of digital computers.', 'start': 884.07, 'duration': 1.28},\n",
              " {'text': 'Whether the neural net\\nis 96% or 98% confident',\n",
              "  'start': 885.35,\n",
              "  'duration': 3.64},\n",
              " {'text': 'the image contains a chicken,', 'start': 888.99, 'duration': 1.42},\n",
              " {'text': \"it doesn't really matter,\\nit's still a chicken.\",\n",
              "  'start': 890.41,\n",
              "  'duration': 2.4},\n",
              " {'text': 'So slight variability in components',\n",
              "  'start': 892.81,\n",
              "  'duration': 2.06},\n",
              " {'text': 'or conditions can be tolerated.',\n",
              "  'start': 894.87,\n",
              "  'duration': 2.502},\n",
              " {'text': '(upbeat rock music)', 'start': 897.372, 'duration': 1.438},\n",
              " {'text': 'I went to an analog\\ncomputing startup in Texas,',\n",
              "  'start': 898.81,\n",
              "  'duration': 2.56},\n",
              " {'text': 'called Mythic AI.', 'start': 901.37, 'duration': 2.0},\n",
              " {'text': \"Here, they're creating analog\\nchips to run neural networks.\",\n",
              "  'start': 903.37,\n",
              "  'duration': 3.45},\n",
              " {'text': 'And they demonstrated\\nseveral AI algorithms for me.',\n",
              "  'start': 906.82,\n",
              "  'duration': 3.103},\n",
              " {'text': '- Oh, there you go.', 'start': 910.98, 'duration': 0.833},\n",
              " {'text': \"See, it's getting you.\\n(Derek laughs)\",\n",
              "  'start': 911.813,\n",
              "  'duration': 1.477},\n",
              " {'text': \"Yeah.\\n- That's fascinating.\", 'start': 913.29, 'duration': 1.48},\n",
              " {'text': '- The biggest use case is\\naugmented in virtual reality.',\n",
              "  'start': 914.77,\n",
              "  'duration': 2.86},\n",
              " {'text': 'If your friend is in a different,',\n",
              "  'start': 917.63,\n",
              "  'duration': 1.52},\n",
              " {'text': \"they're at their house\\nand you're at your house,\",\n",
              "  'start': 919.15,\n",
              "  'duration': 1.56},\n",
              " {'text': 'you can actually render each\\nother in the virtual world.',\n",
              "  'start': 920.71,\n",
              "  'duration': 3.41},\n",
              " {'text': 'So it needs to really\\nquickly capture your pose,',\n",
              "  'start': 924.12,\n",
              "  'duration': 3.16},\n",
              " {'text': 'and then render it in the VR world.',\n",
              "  'start': 927.28,\n",
              "  'duration': 2.07},\n",
              " {'text': '- So, hang on, is this\\nfor the metaverse thing?',\n",
              "  'start': 929.35,\n",
              "  'duration': 1.983},\n",
              " {'text': '- Yeah, this is a very\\nmetaverse application.',\n",
              "  'start': 931.333,\n",
              "  'duration': 4.307},\n",
              " {'text': 'This is depth estimation\\nfrom just a single webcam.',\n",
              "  'start': 935.64,\n",
              "  'duration': 2.99},\n",
              " {'text': \"It's just taking this scene,\", 'start': 938.63, 'duration': 1.32},\n",
              " {'text': \"and then it's doing a heat map.\",\n",
              "  'start': 939.95,\n",
              "  'duration': 1.41},\n",
              " {'text': \"So if it's bright, it means it's close.\",\n",
              "  'start': 941.36,\n",
              "  'duration': 2.39},\n",
              " {'text': \"And if it's far away, it makes it black.\",\n",
              "  'start': 943.75,\n",
              "  'duration': 2.23},\n",
              " {'text': '- [Derek] Now all these\\nalgorithms can be run',\n",
              "  'start': 945.98,\n",
              "  'duration': 1.58},\n",
              " {'text': 'on digital computers,', 'start': 947.56, 'duration': 1.29},\n",
              " {'text': 'but here, the matrix multiplication\\nis actually taking place',\n",
              "  'start': 948.85,\n",
              "  'duration': 3.4},\n",
              " {'text': 'in the analog domain.\\n(light music)',\n",
              "  'start': 952.25,\n",
              "  'duration': 2.17},\n",
              " {'text': 'To make this possible,', 'start': 954.42, 'duration': 1.38},\n",
              " {'text': 'Mythic has repurposed\\ndigital flash storage cells.',\n",
              "  'start': 955.8,\n",
              "  'duration': 3.69},\n",
              " {'text': 'Normally these are used as memory',\n",
              "  'start': 959.49,\n",
              "  'duration': 1.72},\n",
              " {'text': 'to store either a one or a zero.',\n",
              "  'start': 961.21,\n",
              "  'duration': 2.42},\n",
              " {'text': 'If you apply a large positive\\nvoltage to the control gate,',\n",
              "  'start': 963.63,\n",
              "  'duration': 3.83},\n",
              " {'text': 'electrons tunnel up through\\nan insulating barrier',\n",
              "  'start': 967.46,\n",
              "  'duration': 2.75},\n",
              " {'text': 'and become trapped on the floating gate.',\n",
              "  'start': 970.21,\n",
              "  'duration': 2.23},\n",
              " {'text': 'Remove the voltage,', 'start': 972.44, 'duration': 1.13},\n",
              " {'text': 'and the electrons can\\nremain on the floating gate',\n",
              "  'start': 973.57,\n",
              "  'duration': 1.87},\n",
              " {'text': 'for decades, preventing the\\ncell from conducting current.',\n",
              "  'start': 975.44,\n",
              "  'duration': 3.169},\n",
              " {'text': \"And that's how you can store\\neither a one or a zero.\",\n",
              "  'start': 978.609,\n",
              "  'duration': 2.711},\n",
              " {'text': 'You can read out the stored value',\n",
              "  'start': 981.32,\n",
              "  'duration': 1.64},\n",
              " {'text': 'by applying a small voltage.', 'start': 982.96, 'duration': 2.1},\n",
              " {'text': 'If there are electrons\\non the floating gate,',\n",
              "  'start': 985.06,\n",
              "  'duration': 1.91},\n",
              " {'text': \"no current flows, so that's a zero.\",\n",
              "  'start': 986.97,\n",
              "  'duration': 2.61},\n",
              " {'text': \"If there aren't electrons,\", 'start': 989.58, 'duration': 1.36},\n",
              " {'text': \"then current does flow, and that's a one.\",\n",
              "  'start': 990.94,\n",
              "  'duration': 2.98},\n",
              " {'text': \"Now Mythic's idea is to use these cells\",\n",
              "  'start': 993.92,\n",
              "  'duration': 2.11},\n",
              " {'text': 'not as on/off switches,\\nbut as variable resistors.',\n",
              "  'start': 996.03,\n",
              "  'duration': 3.97},\n",
              " {'text': 'They do this by putting a\\nspecific number of electrons',\n",
              "  'start': 1000.0,\n",
              "  'duration': 2.9},\n",
              " {'text': 'on each floating gate,\\ninstead of all or nothing.',\n",
              "  'start': 1002.9,\n",
              "  'duration': 2.77},\n",
              " {'text': 'The greater the number of electrons,',\n",
              "  'start': 1005.67,\n",
              "  'duration': 1.66},\n",
              " {'text': 'the higher the resistance of the channel.',\n",
              "  'start': 1007.33,\n",
              "  'duration': 2.48},\n",
              " {'text': 'When you later apply a small voltage,',\n",
              "  'start': 1009.81,\n",
              "  'duration': 2.19},\n",
              " {'text': 'the current that flows\\nis equal to V over R.',\n",
              "  'start': 1012.0,\n",
              "  'duration': 3.72},\n",
              " {'text': 'But you can also think of this\\nas voltage times conductance,',\n",
              "  'start': 1015.72,\n",
              "  'duration': 3.53},\n",
              " {'text': 'where conductance is just\\nthe reciprocal of resistance.',\n",
              "  'start': 1019.25,\n",
              "  'duration': 3.26},\n",
              " {'text': 'So a single flash cell can be used',\n",
              "  'start': 1022.51,\n",
              "  'duration': 1.96},\n",
              " {'text': 'to multiply two values together,\\nvoltage times conductance.',\n",
              "  'start': 1024.47,\n",
              "  'duration': 4.66},\n",
              " {'text': 'So to use this to run an\\nartificial neural network,',\n",
              "  'start': 1029.13,\n",
              "  'duration': 2.73},\n",
              " {'text': 'well they first write all the\\nweights to the flash cells',\n",
              "  'start': 1031.86,\n",
              "  'duration': 2.89},\n",
              " {'text': \"as each cell's conductance.\", 'start': 1034.75, 'duration': 2.12},\n",
              " {'text': 'Then, they input the activation values',\n",
              "  'start': 1036.87,\n",
              "  'duration': 2.4},\n",
              " {'text': 'as the voltage on the cells.', 'start': 1039.27, 'duration': 2.22},\n",
              " {'text': 'And the resulting current is the product',\n",
              "  'start': 1041.49,\n",
              "  'duration': 2.14},\n",
              " {'text': 'of voltage times conductance,', 'start': 1043.63, 'duration': 1.87},\n",
              " {'text': 'which is activation times weight.',\n",
              "  'start': 1045.5,\n",
              "  'duration': 2.8},\n",
              " {'text': 'The cells are wired together in such a way',\n",
              "  'start': 1048.3,\n",
              "  'duration': 2.56},\n",
              " {'text': 'that the current from each\\nmultiplication adds together,',\n",
              "  'start': 1050.86,\n",
              "  'duration': 3.14},\n",
              " {'text': 'completing the matrix multiplication.',\n",
              "  'start': 1054.0,\n",
              "  'duration': 2.607},\n",
              " {'text': '(light music)', 'start': 1056.607, 'duration': 2.433},\n",
              " {'text': '- So this is our first product.',\n",
              "  'start': 1059.04,\n",
              "  'duration': 1.88},\n",
              " {'text': 'This can do 25 trillion\\nmath operations per second.',\n",
              "  'start': 1060.92,\n",
              "  'duration': 4.94},\n",
              " {'text': '- [Derek] 25 trillion.', 'start': 1065.86, 'duration': 1.18},\n",
              " {'text': '- Yep, 25 trillion math\\noperations per second,',\n",
              "  'start': 1067.04,\n",
              "  'duration': 2.36},\n",
              " {'text': 'in this little chip here,', 'start': 1069.4, 'duration': 1.14},\n",
              " {'text': 'burning about three watts of power.',\n",
              "  'start': 1070.54,\n",
              "  'duration': 2.08},\n",
              " {'text': '- [Derek] How does it\\ncompare to a digital chip?',\n",
              "  'start': 1072.62,\n",
              "  'duration': 2.31},\n",
              " {'text': '- The newer digital\\nsystems can do anywhere',\n",
              "  'start': 1074.93,\n",
              "  'duration': 2.97},\n",
              " {'text': 'from 25 to 100 trillion\\noperations per second,',\n",
              "  'start': 1077.9,\n",
              "  'duration': 2.78},\n",
              " {'text': 'but they are big, thousand-dollar systems',\n",
              "  'start': 1080.68,\n",
              "  'duration': 2.1},\n",
              " {'text': 'that are spitting out 50\\nto 100 watts of power.',\n",
              "  'start': 1082.78,\n",
              "  'duration': 3.81},\n",
              " {'text': \"- [Derek] Obviously this isn't\",\n",
              "  'start': 1086.59,\n",
              "  'duration': 1.09},\n",
              " {'text': 'like an apples apples comparison, right?',\n",
              "  'start': 1087.68,\n",
              "  'duration': 1.78},\n",
              " {'text': \"- No, it's not apples to apples.\",\n",
              "  'start': 1089.46,\n",
              "  'duration': 1.12},\n",
              " {'text': 'I mean, training those algorithms,',\n",
              "  'start': 1090.58,\n",
              "  'duration': 3.08},\n",
              " {'text': 'you need big hardware like this.',\n",
              "  'start': 1093.66,\n",
              "  'duration': 1.85},\n",
              " {'text': 'You can just do all sorts\\nof stuff on the GPU,',\n",
              "  'start': 1095.51,\n",
              "  'duration': 2.1},\n",
              " {'text': 'but if you specifically\\nare doing AI workloads',\n",
              "  'start': 1097.61,\n",
              "  'duration': 2.75},\n",
              " {'text': \"and you wanna deploy 'em,\\nyou could use this instead.\",\n",
              "  'start': 1100.36,\n",
              "  'duration': 2.36},\n",
              " {'text': 'You can imagine them in security cameras,',\n",
              "  'start': 1102.72,\n",
              "  'duration': 2.45},\n",
              " {'text': 'autonomous systems,', 'start': 1105.17, 'duration': 1.52},\n",
              " {'text': 'inspection equipment for manufacturing.',\n",
              "  'start': 1106.69,\n",
              "  'duration': 2.43},\n",
              " {'text': 'Every time they make a Frito-Lay chip,',\n",
              "  'start': 1109.12,\n",
              "  'duration': 1.76},\n",
              " {'text': 'they inspect it with a camera,',\n",
              "  'start': 1110.88,\n",
              "  'duration': 1.32},\n",
              " {'text': 'and the bad Fritos get blown\\noff of the conveyor belt.',\n",
              "  'start': 1112.2,\n",
              "  'duration': 3.97},\n",
              " {'text': \"But they're using artificial intelligence\",\n",
              "  'start': 1116.17,\n",
              "  'duration': 1.58},\n",
              " {'text': 'to spot which Fritos are good and bad.',\n",
              "  'start': 1117.75,\n",
              "  'duration': 2.66},\n",
              " {'text': '- Some have proposed\\nusing analog circuitry',\n",
              "  'start': 1120.41,\n",
              "  'duration': 2.24},\n",
              " {'text': 'in smart home speakers,', 'start': 1122.65, 'duration': 1.27},\n",
              " {'text': 'solely to listen for the wake\\nword, like Alexa or Siri.',\n",
              "  'start': 1123.92,\n",
              "  'duration': 3.73},\n",
              " {'text': 'They would use a lot less\\npower and be able to quickly',\n",
              "  'start': 1127.65,\n",
              "  'duration': 2.29},\n",
              " {'text': 'and reliably turn on the\\ndigital circuitry of the device.',\n",
              "  'start': 1129.94,\n",
              "  'duration': 3.37},\n",
              " {'text': 'But you still have to deal\\nwith the challenges of analog.',\n",
              "  'start': 1133.31,\n",
              "  'duration': 3.11},\n",
              " {'text': '- So for one of the popular networks,',\n",
              "  'start': 1136.42,\n",
              "  'duration': 1.7},\n",
              " {'text': 'there would be 50 sequences', 'start': 1138.12, 'duration': 2.62},\n",
              " {'text': \"of matrix multiplies that you're doing.\",\n",
              "  'start': 1140.74,\n",
              "  'duration': 1.93},\n",
              " {'text': 'Now, if you did that entirely\\nin the analog domain,',\n",
              "  'start': 1142.67,\n",
              "  'duration': 2.37},\n",
              " {'text': 'by the time it gets to the output,',\n",
              "  'start': 1145.04,\n",
              "  'duration': 1.3},\n",
              " {'text': \"it's just so distorted\", 'start': 1146.34, 'duration': 1.47},\n",
              " {'text': \"that you don't have any result at all.\",\n",
              "  'start': 1147.81,\n",
              "  'duration': 2.45},\n",
              " {'text': 'So you convert it from the analog domain,',\n",
              "  'start': 1150.26,\n",
              "  'duration': 1.87},\n",
              " {'text': 'back to the digital domain,', 'start': 1152.13, 'duration': 1.96},\n",
              " {'text': 'send it to the next processing block,',\n",
              "  'start': 1154.09,\n",
              "  'duration': 1.88},\n",
              " {'text': 'and then you convert it into\\nthe analog domain again.',\n",
              "  'start': 1155.97,\n",
              "  'duration': 2.39},\n",
              " {'text': 'And that allows you to\\npreserve the signal.',\n",
              "  'start': 1158.36,\n",
              "  'duration': 2.13},\n",
              " {'text': '- You know, when Rosenblatt\\nwas first setting',\n",
              "  'start': 1160.49,\n",
              "  'duration': 2.15},\n",
              " {'text': 'up his perceptron,', 'start': 1162.64, 'duration': 1.11},\n",
              " {'text': 'he used a digital IBM computer.',\n",
              "  'start': 1163.75,\n",
              "  'duration': 2.95},\n",
              " {'text': 'Finding it too slow,', 'start': 1166.7, 'duration': 1.63},\n",
              " {'text': 'he built a custom analog computer,',\n",
              "  'start': 1168.33,\n",
              "  'duration': 2.51},\n",
              " {'text': 'complete with variable resistors',\n",
              "  'start': 1170.84,\n",
              "  'duration': 1.73},\n",
              " {'text': 'and little motors to drive them.',\n",
              "  'start': 1172.57,\n",
              "  'duration': 2.72},\n",
              " {'text': 'Ultimately, his idea of neural networks',\n",
              "  'start': 1175.29,\n",
              "  'duration': 2.52},\n",
              " {'text': 'turned out to be right.', 'start': 1177.81, 'duration': 1.59},\n",
              " {'text': 'Maybe he was right about analog, too.',\n",
              "  'start': 1179.4,\n",
              "  'duration': 2.973},\n",
              " {'text': \"Now, I can't say whether\\nanalog computers will take\",\n",
              "  'start': 1183.25,\n",
              "  'duration': 2.92},\n",
              " {'text': 'off the way digital did last century,',\n",
              "  'start': 1186.17,\n",
              "  'duration': 2.52},\n",
              " {'text': 'but they do seem to be better suited',\n",
              "  'start': 1188.69,\n",
              "  'duration': 2.67},\n",
              " {'text': 'to a lot of the tasks\\nthat we want computers',\n",
              "  'start': 1191.36,\n",
              "  'duration': 2.19},\n",
              " {'text': 'to perform today,', 'start': 1193.55, 'duration': 1.66},\n",
              " {'text': 'which is a little bit funny', 'start': 1195.21, 'duration': 1.03},\n",
              " {'text': 'because I always thought of digital',\n",
              "  'start': 1196.24,\n",
              "  'duration': 1.84},\n",
              " {'text': 'as the optimal way of\\nprocessing information.',\n",
              "  'start': 1198.08,\n",
              "  'duration': 3.45},\n",
              " {'text': 'Everything from music to pictures,',\n",
              "  'start': 1201.53,\n",
              "  'duration': 2.24},\n",
              " {'text': 'to video has all gone\\ndigital in the last 50 years.',\n",
              "  'start': 1203.77,\n",
              "  'duration': 4.09},\n",
              " {'text': 'But maybe in a 100 years,', 'start': 1207.86, 'duration': 1.81},\n",
              " {'text': 'we will look back on digital,',\n",
              "  'start': 1209.67,\n",
              "  'duration': 1.437},\n",
              " {'text': 'not not as the end point\\nof information technology,',\n",
              "  'start': 1211.107,\n",
              "  'duration': 3.953},\n",
              " {'text': 'but as a starting point.', 'start': 1215.06, 'duration': 2.26},\n",
              " {'text': 'Our brains are digital', 'start': 1217.32, 'duration': 1.75},\n",
              " {'text': \"in that a neuron either\\nfires or it doesn't,\",\n",
              "  'start': 1219.07,\n",
              "  'duration': 2.86},\n",
              " {'text': \"but they're also analog\", 'start': 1221.93, 'duration': 2.11},\n",
              " {'text': 'in that thinking takes place\\neverywhere, all at once.',\n",
              "  'start': 1224.04,\n",
              "  'duration': 4.18},\n",
              " {'text': 'So maybe what we need', 'start': 1228.22, 'duration': 1.85},\n",
              " {'text': 'to achieve true artificial intelligence,',\n",
              "  'start': 1230.07,\n",
              "  'duration': 2.42},\n",
              " {'text': 'machines that think like\\nus, is the power of analog.',\n",
              "  'start': 1232.49,\n",
              "  'duration': 4.644},\n",
              " {'text': '(gentle music)', 'start': 1237.134, 'duration': 2.583},\n",
              " {'text': 'Hey, I learned a lot\\nwhile making this video,',\n",
              "  'start': 1242.04,\n",
              "  'duration': 2.27},\n",
              " {'text': 'much of it by playing with\\nan actual analog computer.',\n",
              "  'start': 1244.31,\n",
              "  'duration': 2.97},\n",
              " {'text': 'You know, trying things out for yourself',\n",
              "  'start': 1247.28,\n",
              "  'duration': 1.53},\n",
              " {'text': 'is really the best way to learn,',\n",
              "  'start': 1248.81,\n",
              "  'duration': 1.49},\n",
              " {'text': 'and you can do that with this\\nvideo sponsor, Brilliant.',\n",
              "  'start': 1250.3,\n",
              "  'duration': 3.17},\n",
              " {'text': 'Brilliant is a website and app',\n",
              "  'start': 1253.47,\n",
              "  'duration': 1.36},\n",
              " {'text': 'that gets you thinking deeply', 'start': 1254.83, 'duration': 1.23},\n",
              " {'text': 'by engaging you in problem-solving.',\n",
              "  'start': 1256.06,\n",
              "  'duration': 2.14},\n",
              " {'text': 'They have a great course\\non neural networks,',\n",
              "  'start': 1258.2,\n",
              "  'duration': 1.85},\n",
              " {'text': 'where you can test how\\nit works for yourself.',\n",
              "  'start': 1260.05,\n",
              "  'duration': 2.41},\n",
              " {'text': 'It gives you an excellent intuition',\n",
              "  'start': 1262.46,\n",
              "  'duration': 1.83},\n",
              " {'text': 'about how neural networks can\\nrecognize numbers and shapes,',\n",
              "  'start': 1264.29,\n",
              "  'duration': 3.1},\n",
              " {'text': 'and it also allows you to\\nexperience the importance',\n",
              "  'start': 1267.39,\n",
              "  'duration': 2.16},\n",
              " {'text': 'of good training data and hidden layers',\n",
              "  'start': 1269.55,\n",
              "  'duration': 2.3},\n",
              " {'text': 'to understand why more sophisticated',\n",
              "  'start': 1271.85,\n",
              "  'duration': 2.19},\n",
              " {'text': 'neural networks work better.', 'start': 1274.04, 'duration': 1.82},\n",
              " {'text': 'What I love about Brilliant', 'start': 1275.86, 'duration': 1.08},\n",
              " {'text': 'is it tests your knowledge as you go.',\n",
              "  'start': 1276.94,\n",
              "  'duration': 2.38},\n",
              " {'text': 'The lessons are highly interactive,',\n",
              "  'start': 1279.32,\n",
              "  'duration': 1.49},\n",
              " {'text': 'and they get progressively\\nharder as you go on.',\n",
              "  'start': 1280.81,\n",
              "  'duration': 2.65},\n",
              " {'text': 'And if you get stuck, there\\nare always helpful hints.',\n",
              "  'start': 1283.46,\n",
              "  'duration': 3.16},\n",
              " {'text': 'For viewers of this video,', 'start': 1286.62, 'duration': 1.15},\n",
              " {'text': 'Brilliant is offering the first 200 people',\n",
              "  'start': 1287.77,\n",
              "  'duration': 1.8},\n",
              " {'text': '20% off an annual premium subscription.',\n",
              "  'start': 1289.57,\n",
              "  'duration': 2.53},\n",
              " {'text': 'Just go to brilliant.org/veritasium.',\n",
              "  'start': 1292.1,\n",
              "  'duration': 3.11},\n",
              " {'text': 'I will put that link\\ndown in the description.',\n",
              "  'start': 1295.21,\n",
              "  'duration': 2.22},\n",
              " {'text': 'So I wanna thank Brilliant\\nfor supporting Veritasium,',\n",
              "  'start': 1297.43,\n",
              "  'duration': 2.6},\n",
              " {'text': 'and I wanna thank you for watching.',\n",
              "  'start': 1300.03,\n",
              "  'duration': 1.75}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import json library to make usable\n",
        "import json\n",
        "text_raw = json.loads(json_formatted)\n",
        "text_raw\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFX-hqV5AkEz"
      },
      "source": [
        "Popular sites include Clipconverter, Free CC Converter Tool, Keepvid (also offers video download), and Way With Words. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(text_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'analog computers were the most\\npowerful computers on Earth,',\n",
              " 'start': 1.35,\n",
              " 'duration': 3.75}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_raw[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'- For hundreds of years,'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_raw[0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>start</th>\n",
              "      <th>duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>- For hundreds of years,</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>analog computers were the most\\npowerful compu...</td>\n",
              "      <td>1.35</td>\n",
              "      <td>3.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>predicting eclipses, tides,\\nand guiding anti-...</td>\n",
              "      <td>5.10</td>\n",
              "      <td>4.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Then, with the advent of\\nsolid-state transist...</td>\n",
              "      <td>9.72</td>\n",
              "      <td>2.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>digital computers took off.</td>\n",
              "      <td>12.65</td>\n",
              "      <td>1.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>20% off an annual premium subscription.</td>\n",
              "      <td>1289.57</td>\n",
              "      <td>2.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>Just go to brilliant.org/veritasium.</td>\n",
              "      <td>1292.10</td>\n",
              "      <td>3.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>I will put that link\\ndown in the description.</td>\n",
              "      <td>1295.21</td>\n",
              "      <td>2.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>So I wanna thank Brilliant\\nfor supporting Ver...</td>\n",
              "      <td>1297.43</td>\n",
              "      <td>2.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>and I wanna thank you for watching.</td>\n",
              "      <td>1300.03</td>\n",
              "      <td>1.75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>526 rows  3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text    start  duration\n",
              "0                             - For hundreds of years,     0.00      1.35\n",
              "1    analog computers were the most\\npowerful compu...     1.35      3.75\n",
              "2    predicting eclipses, tides,\\nand guiding anti-...     5.10      4.62\n",
              "3    Then, with the advent of\\nsolid-state transist...     9.72      2.93\n",
              "4                          digital computers took off.    12.65      1.85\n",
              "..                                                 ...      ...       ...\n",
              "521            20% off an annual premium subscription.  1289.57      2.53\n",
              "522               Just go to brilliant.org/veritasium.  1292.10      3.11\n",
              "523     I will put that link\\ndown in the description.  1295.21      2.22\n",
              "524  So I wanna thank Brilliant\\nfor supporting Ver...  1297.43      2.60\n",
              "525                and I wanna thank you for watching.  1300.03      1.75\n",
              "\n",
              "[526 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "text_df = pd.DataFrame(text_raw)\n",
        "text_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Saving only the text column\n",
        "text = text_df['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Series([], Name: text, dtype: object)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# text = text.filter(regex=r'/n')\n",
        "# text = text.replace(\"\\n\", str())\n",
        "# text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          - For hundreds of years,\n",
            "analog computers were the most\\npowerful comput...\n",
            "predicting eclipses, tides,\\nand guiding anti-a...\n",
            "Then, with the advent of\\nsolid-state transistors,\n",
            "                       digital computers took off.\n",
            " Now, virtually every\\ncomputer we use is digital.\n",
            "But today, a perfect storm of\\nfactors is setti...\n",
            "            for a resurgence of analog technology.\n",
            "                       This is an analog computer,\n",
            "and by connecting these\\nwires in particular ways,\n",
            "           I can program it to solve a whole range\n",
            "                        of differential equations.\n",
            "    For example, this setup\\nallows me to simulate\n",
            "            a damped mass oscillating on a spring.\n",
            "So on the oscilloscope, you\\ncan actually see t...\n",
            "                            of the mass over time.\n",
            "                       And I can vary the damping,\n",
            "                           or the spring constant,\n",
            "    or the mass, and we can\\nsee how the amplitude\n",
            "          and duration of the oscillations change.\n",
            "            Now what makes this an analog computer\n",
            "     is that there are no\\nzeros and ones in here.\n",
            "Instead, there's actually\\na voltage that oscil...\n",
            "     up and down exactly\\nlike a mass on a spring.\n",
            "             The electrical circuitry is an analog\n",
            "                         for the physical problem,\n",
            "                  it just takes place much faster.\n",
            "     Now, if I change the\\nelectrical connections,\n",
            "                       I can program this computer\n",
            "            to solve other differential equations,\n",
            "                           like the Lorenz system,\n",
            "which is a basic model of\\nconvection in the at...\n",
            "Now the Lorenz system is\\nfamous because it was...\n",
            "        of the first discovered examples of chaos.\n",
            "        And here, you can see the Lorenz attractor\n",
            "               with its beautiful butterfly shape.\n",
            "                      And on this analog computer,\n",
            "                       I can change the parameters\n",
            "               and see their effects in real time.\n",
            "                 So these examples illustrate some\n",
            "            of the advantages of analog computers.\n",
            "  They are incredibly\\npowerful computing devices,\n",
            "and they can complete a\\nlot of computations fast.\n",
            "        Plus, they don't take much power to do it.\n",
            "                          With a digital computer,\n",
            "           if you wanna add two eight-bit numbers,\n",
            "                   you need around 50 transistors,\n",
            "                  whereas with an analog computer,\n",
            "                         you can add two currents,\n",
            "                     just by connecting two wires.\n",
            " With a digital computer\\nto multiply two numbers,\n",
            "        you need on the order of 1,000 transistors\n",
            "                     all switching zeros and ones,\n",
            "                  whereas with an analog computer,\n",
            "        you can pass a current through a resistor,\n",
            "         and then the voltage across this resistor\n",
            "                                will be I times R.\n",
            "                                   So effectively,\n",
            "         you have multiplied two numbers together.\n",
            "  But analog computers also\\nhave their drawbacks.\n",
            "                                    For one thing,\n",
            "  they are not general-purpose\\ncomputing devices.\n",
            "I mean, you're not gonna run\\nMicrosoft Word on...\n",
            "And also, since the inputs\\nand outputs are con...\n",
            "                       I can't input exact values.\n",
            "      So if I try to repeat\\nthe same calculation,\n",
            "    I'm never going to get\\nthe exact same answer.\n",
            "Plus, think about\\nmanufacturing analog computers.\n",
            "            There's always gonna be some variation\n",
            "                 in the exact value of components,\n",
            "                     like resistors or capacitors.\n",
            "                    So as a general rule of thumb,\n",
            "                  you can expect about a 1% error.\n",
            "            So when you think of analog computers,\n",
            "you can think powerful,\\nfast, and energy-effic...\n",
            "but also single-purpose,\\nnon-repeatable, and i...\n",
            "            And if those sound like deal-breakers,\n",
            "                   it's because they probably are.\n",
            "               I think these are the major reasons\n",
            "            why analog computers fell out of favor\n",
            "      as soon as digital\\ncomputers became viable.\n",
            "Now, here's why analog computers\\nmay be making...\n",
            "                               (computers beeping)\n",
            "      It all starts with\\nartificial intelligence.\n",
            "- [Narrator] A machine\\nhas been programmed to see\n",
            "                              and to move objects.\n",
            "                                   - AI isn't new.\n",
            "                 The term was coined back in 1956.\n",
            "         In 1958, Cornell University psychologist,\n",
            "           Frank Rosenblatt, built the perceptron,\n",
            "designed to mimic how\\nneurons fire in our brains.\n",
            "So here's a basic model of how\\nneurons in our ...\n",
            "     An individual neuron\\ncan either fire or not,\n",
            "    so its level of activation\\ncan be represented\n",
            "                               as a one or a zero.\n",
            "                           The input to one neuron\n",
            "         is the output from a bunch other neurons,\n",
            "             but the strength of these connections\n",
            "                           between neurons varies,\n",
            "     so each one can be given\\na different weight.\n",
            "                  Some connections are excitatory,\n",
            "                    so they have positive weights,\n",
            "                      while others are inhibitory,\n",
            "                    so they have negative weights.\n",
            "                         And the way to figure out\n",
            "                whether a particular neuron fires,\n",
            "   is to take the activation\\nof each input neuron\n",
            "                       and multiply by its weight,\n",
            "                  and then add these all together.\n",
            "If their sum is greater than\\nsome number calle...\n",
            "                            then the neuron fires,\n",
            "but if it's less than that,\\nthe neuron doesn't...\n",
            "As input, Rosenblatt's\\nperceptron had 400 phot...\n",
            "                        arranged in a square grid,\n",
            "                to capture a 20 by 20-pixel image.\n",
            "  You can think of each\\npixel as an input neuron,\n",
            "with its activation being\\nthe brightness of th...\n",
            "                       Although strictly speaking,\n",
            "     the activation should\\nbe either zero or one,\n",
            "we can let it take any\\nvalue between zero and ...\n",
            "                All of these neurons are connected\n",
            "                        to a single output neuron,\n",
            "               each via its own adjustable weight.\n",
            "         So to see if the output neuron will fire,\n",
            "you multiply the activation\\nof each neuron by ...\n",
            "                            and add them together.\n",
            "         This is essentially a vector dot product.\n",
            "If the answer is larger than\\nthe bias, the neu...\n",
            "                           and if not, it doesn't.\n",
            "                    Now the goal of the perceptron\n",
            "  was to reliably distinguish\\nbetween two images,\n",
            "                    like a rectangle and a circle.\n",
            "                                      For example,\n",
            "               the output neuron could always fire\n",
            "                     when presented with a circle,\n",
            "        but never when presented with a rectangle.\n",
            "To achieve this, the\\nperception had to be trai...\n",
            "     that is, shown a series\\nof different circles\n",
            "and rectangles, and have its\\nweights adjusted ...\n",
            "         We can visualize the weights as an image,\n",
            "since there's a unique weight\\nfor each pixel o...\n",
            "Initially, Rosenblatt set\\nall the weights to z...\n",
            "            If the perceptron's output is correct,\n",
            "          for example, here it's shown a rectangle\n",
            "               and the output neuron doesn't fire,\n",
            "                 no change is made to the weights.\n",
            "But if it's wrong, then\\nthe weights are adjusted.\n",
            "            The algorithm for updating the weights\n",
            "                             is remarkably simple.\n",
            "Here, the output neuron didn't\\nfire when it wa...\n",
            "                    because it was shown a circle.\n",
            "                         So to modify the weights,\n",
            "you simply add the input\\nactivations to the we...\n",
            "    If the output neuron\\nfires when it shouldn't,\n",
            "                like here, when shown a rectangle,\n",
            "    well, then you subtract\\nthe input activations\n",
            "         from the weights, and you keep doing this\n",
            "         until the perceptron correctly identifies\n",
            "                          all the training images.\n",
            "It was shown that this\\nalgorithm will always c...\n",
            "so long as it's possible\\nto map the two catego...\n",
            "                             into distinct groups.\n",
            "                              (footsteps thumping)\n",
            "     The perceptron was\\ncapable of distinguishing\n",
            "between different shapes,\\nlike rectangles and ...\n",
            "                     or between different letters.\n",
            "                      And according to Rosenblatt,\n",
            "it could even tell the\\ndifference between cats...\n",
            "                   He said the machine was capable\n",
            "              of what amounts to original thought,\n",
            "                       and the media lapped it up.\n",
            "        The \"New York Times\" called the perceptron\n",
            "             \"the embryo of an electronic computer\n",
            "that the Navy expects will\\nbe able to walk, talk,\n",
            "                     see, write, reproduce itself,\n",
            "               and be conscious of its existence.\"\n",
            " - [Narrator] After training\\non lots of examples,\n",
            "           it's given new faces it has never seen,\n",
            "and is able to successfully\\ndistinguish male f...\n",
            "                                   It has learned.\n",
            "  - In reality, the perceptron\\nwas pretty limited\n",
            "                              in what it could do.\n",
            "It could not, in fact,\\ntell apart dogs from cats.\n",
            "              This and other critiques were raised\n",
            "in a book by MIT giants,\\nMinsky and Papert, in...\n",
            "                     And that led to a bust period\n",
            "for artificial neural\\nnetworks and AI in general.\n",
            "                It's known as the first AI winter.\n",
            "           Rosenblatt did not survive this winter.\n",
            "        He drowned while sailing in Chesapeake Bay\n",
            "                             on his 43rd birthday.\n",
            "                             (mellow upbeat music)\n",
            " - [Narrator] The NAV Lab\\nis a road-worthy truck,\n",
            "         modified so that researchers or computers\n",
            "     can control the vehicle\\nas occasion demands.\n",
            "- [Derek] In the 1980s,\\nthere was an AI resurg...\n",
            "  when researchers at\\nCarnegie Mellon created one\n",
            "                   of the first self-driving cars.\n",
            "                           The vehicle was steered\n",
            "   by an artificial neural\\nnetwork called ALVINN.\n",
            "                 It was similar to the perceptron,\n",
            "except it had a hidden\\nlayer of artificial neu...\n",
            "                     between the input and output.\n",
            "  As input, ALVINN received\\n30 by 32-pixel images\n",
            "                                of the road ahead.\n",
            "        Here, I'm showing them as 60 by 64 pixels.\n",
            "    But each of these input\\nneurons was connected\n",
            "via an adjustable weight to a\\nhidden layer of ...\n",
            "  These were each connected\\nto 32 output neurons.\n",
            "So to go from one layer of\\nthe network to the ...\n",
            "              you perform a matrix multiplication:\n",
            "           the input activation times the weights.\n",
            "   The output neuron with\\nthe greatest activation\n",
            "                    determines the steering angle.\n",
            "                          To train the neural net,\n",
            "                        a human drove the vehicle,\n",
            "              providing the correct steering angle\n",
            "                          for a given input image.\n",
            "All the weights in the\\nneural network were adj...\n",
            "                              through the training\n",
            "      so that ALVINN's output\\nbetter matched that\n",
            "                              of the human driver.\n",
            "              The method for adjusting the weights\n",
            "                        is called backpropagation,\n",
            "                       which I won't go into here,\n",
            "        but Welch Labs has a great series on this,\n",
            "            which I'll link to in the description.\n",
            "              Again, you can visualize the weights\n",
            "            for the four hidden neurons as images.\n",
            "      The weights are initially\\nset to be random,\n",
            "                       but as training progresses,\n",
            "the computer learns to pick\\nup on certain patt...\n",
            "You can see the road markings\\nemerge in the we...\n",
            "Simultaneously, the output\\nsteering angle coal...\n",
            "                    onto the human steering angle.\n",
            "    The computer drove the\\nvehicle at a top speed\n",
            "         of around one or two kilometers per hour.\n",
            "                       It was limited by the speed\n",
            "at which the computer could\\nperform matrix mul...\n",
            "                           Despite these advances,\n",
            "        artificial neural networks still struggled\n",
            "                      with seemingly simple tasks,\n",
            "                 like telling apart cats and dogs.\n",
            "                  And no one knew whether hardware\n",
            "                    or software was the weak link.\n",
            "I mean, did we have a good\\nmodel of intelligence,\n",
            "               we just needed more computer power?\n",
            "                    Or, did we have the wrong idea\n",
            "about how to make intelligence\\nsystems altoget...\n",
            "So artificial intelligence\\nexperienced another...\n",
            "                                     in the 1990s.\n",
            "                                 By the mid 2000s,\n",
            "most AI researchers were\\nfocused on improving ...\n",
            "                   But one researcher, Fei-Fei Li,\n",
            "     thought maybe there was\\na different problem.\n",
            "            Maybe these artificial neural networks\n",
            "                just needed more data to train on.\n",
            "So she planned to map out\\nthe entire world of ...\n",
            "          From 2006 to 2009, she created ImageNet,\n",
            "  a database of 1.2 million\\nhuman-labeled images,\n",
            "                                which at the time,\n",
            "was the largest labeled image\\ndataset ever con...\n",
            "                            And from 2010 to 2017,\n",
            "                   ImageNet ran an annual contest:\n",
            "the ImageNet Large Scale\\nVisual Recognition Ch...\n",
            "where software programs\\ncompeted to correctly ...\n",
            "                              and classify images.\n",
            "Images were classified into\\n1,000 different ca...\n",
            "                including 90 different dog breeds.\n",
            "   A neural network competing\\nin this competition\n",
            "     would have an output\\nlayer of 1,000 neurons,\n",
            "        each corresponding to a category of object\n",
            "                   that could appear in the image.\n",
            "   If the image contains,\\nsay, a German shepherd,\n",
            "then the output neuron\\ncorresponding to German...\n",
            "               should have the highest activation.\n",
            "Unsurprisingly, it turned\\nout to be a tough ch...\n",
            "         One way to judge the performance of an AI\n",
            "is to see how often the five\\nhighest neuron ac...\n",
            "              do not include the correct category.\n",
            "           This is the so-called top-5 error rate.\n",
            "In 2010, the best performer\\nhad a top-5 error ...\n",
            "   of 28.2%, meaning that\\nnearly 1/3 of the time,\n",
            "the correct answer was not\\namong its top five ...\n",
            "In 2011, the error rate of\\nthe best performer ...\n",
            "                        a substantial improvement.\n",
            "                                But the next year,\n",
            "                      an artificial neural network\n",
            "  from the University of\\nToronto, called AlexNet,\n",
            "                         blew away the competition\n",
            "            with a top-5 error rate of just 16.4%.\n",
            "   What set AlexNet apart\\nwas its size and depth.\n",
            "            The network consisted of eight layers,\n",
            "                    and in total, 500,000 neurons.\n",
            "                                 To train AlexNet,\n",
            "60 million weights and biases\\nhad to be carefu...\n",
            "                      using the training database.\n",
            "   Because of all the big\\nmatrix multiplications,\n",
            "   processing a single image\\nrequired 700 million\n",
            "                       individual math operations.\n",
            "        So training was computationally intensive.\n",
            "The team managed it by\\npioneering the use of G...\n",
            "                       graphical processing units,\n",
            "which are traditionally used\\nfor driving displ...\n",
            "So they're specialized for\\nfast parallel compu...\n",
            "      The AlexNet paper\\ndescribing their research\n",
            "                                 is a blockbuster.\n",
            "           It's now been cited over 100,000 times,\n",
            "and it identifies the\\nscale of the neural network\n",
            "                            as key to its success.\n",
            "It takes a lot of computation\\nto train and run...\n",
            "  but the improvement in\\nperformance is worth it.\n",
            "                 With others following their lead,\n",
            "                              the top-5 error rate\n",
            "             on the ImageNet competition plummeted\n",
            "in the years that followed,\\ndown to 3.6% in 2015.\n",
            "            That is better than human performance.\n",
            "             The neural network that achieved this\n",
            "                        had 100 layers of neurons.\n",
            "                           So the future is clear:\n",
            "                We will see ever increasing demand\n",
            "                  for ever larger neural networks.\n",
            "        And this is a problem for several reasons:\n",
            "                        One is energy consumption.\n",
            "     Training a neural network\\nrequires an amount\n",
            " of electricity similar\\nto the yearly consumption\n",
            "                              of three households.\n",
            "Another issue is the so-called\\nVon Neumann Bot...\n",
            "           Virtually every modern digital computer\n",
            "                            stores data in memory,\n",
            "        and then accesses it as needed over a bus.\n",
            "When performing the huge\\nmatrix multiplication...\n",
            "                          by deep neural networks,\n",
            "                  most of the time and energy goes\n",
            "          into fetching those weight values rather\n",
            "              than actually doing the computation.\n",
            "And finally, there are the\\nlimitations of Moor...\n",
            "            For decades, the number of transistors\n",
            "on a chip has been doubling\\napproximately ever...\n",
            "                  but now the size of a transistor\n",
            "               is approaching the size of an atom.\n",
            "So there are some fundamental\\nphysical challenges\n",
            "                       to further miniaturization.\n",
            "So this is the perfect\\nstorm for analog comput...\n",
            "     Digital computers are\\nreaching their limits.\n",
            "Meanwhile, neural networks\\nare exploding in po...\n",
            "              and a lot of what they do boils down\n",
            "          to a single task: matrix multiplication.\n",
            "Best of all, neural networks\\ndon't need the pr...\n",
            "                             of digital computers.\n",
            "   Whether the neural net\\nis 96% or 98% confident\n",
            "                     the image contains a chicken,\n",
            "  it doesn't really matter,\\nit's still a chicken.\n",
            "               So slight variability in components\n",
            "                   or conditions can be tolerated.\n",
            "                               (upbeat rock music)\n",
            "  I went to an analog\\ncomputing startup in Texas,\n",
            "                                 called Mythic AI.\n",
            "Here, they're creating analog\\nchips to run neu...\n",
            "And they demonstrated\\nseveral AI algorithms fo...\n",
            "                               - Oh, there you go.\n",
            "            See, it's getting you.\\n(Derek laughs)\n",
            "                      Yeah.\\n- That's fascinating.\n",
            "- The biggest use case is\\naugmented in virtual...\n",
            "                 If your friend is in a different,\n",
            " they're at their house\\nand you're at your house,\n",
            "you can actually render each\\nother in the virt...\n",
            " So it needs to really\\nquickly capture your pose,\n",
            "               and then render it in the VR world.\n",
            "  - So, hang on, is this\\nfor the metaverse thing?\n",
            "    - Yeah, this is a very\\nmetaverse application.\n",
            "This is depth estimation\\nfrom just a single we...\n",
            "                      It's just taking this scene,\n",
            "                   and then it's doing a heat map.\n",
            "           So if it's bright, it means it's close.\n",
            "          And if it's far away, it makes it black.\n",
            "    - [Derek] Now all these\\nalgorithms can be run\n",
            "                             on digital computers,\n",
            "but here, the matrix multiplication\\nis actuall...\n",
            "              in the analog domain.\\n(light music)\n",
            "                            To make this possible,\n",
            "Mythic has repurposed\\ndigital flash storage ce...\n",
            "                 Normally these are used as memory\n",
            "                  to store either a one or a zero.\n",
            "If you apply a large positive\\nvoltage to the c...\n",
            "electrons tunnel up through\\nan insulating barrier\n",
            "          and become trapped on the floating gate.\n",
            "                               Remove the voltage,\n",
            "and the electrons can\\nremain on the floating gate\n",
            "for decades, preventing the\\ncell from conducti...\n",
            "And that's how you can store\\neither a one or a...\n",
            "                 You can read out the stored value\n",
            "                      by applying a small voltage.\n",
            "     If there are electrons\\non the floating gate,\n",
            "               no current flows, so that's a zero.\n",
            "                        If there aren't electrons,\n",
            "         then current does flow, and that's a one.\n",
            "           Now Mythic's idea is to use these cells\n",
            "not as on/off switches,\\nbut as variable resist...\n",
            "They do this by putting a\\nspecific number of e...\n",
            "on each floating gate,\\ninstead of all or nothing.\n",
            "              The greater the number of electrons,\n",
            "         the higher the resistance of the channel.\n",
            "             When you later apply a small voltage,\n",
            "     the current that flows\\nis equal to V over R.\n",
            "But you can also think of this\\nas voltage time...\n",
            "where conductance is just\\nthe reciprocal of re...\n",
            "                So a single flash cell can be used\n",
            "to multiply two values together,\\nvoltage times...\n",
            "So to use this to run an\\nartificial neural net...\n",
            "well they first write all the\\nweights to the f...\n",
            "                       as each cell's conductance.\n",
            "            Then, they input the activation values\n",
            "                      as the voltage on the cells.\n",
            "          And the resulting current is the product\n",
            "                     of voltage times conductance,\n",
            "                 which is activation times weight.\n",
            "        The cells are wired together in such a way\n",
            "that the current from each\\nmultiplication adds...\n",
            "             completing the matrix multiplication.\n",
            "                                     (light music)\n",
            "                   - So this is our first product.\n",
            "This can do 25 trillion\\nmath operations per se...\n",
            "                            - [Derek] 25 trillion.\n",
            "   - Yep, 25 trillion math\\noperations per second,\n",
            "                         in this little chip here,\n",
            "               burning about three watts of power.\n",
            " - [Derek] How does it\\ncompare to a digital chip?\n",
            "      - The newer digital\\nsystems can do anywhere\n",
            "   from 25 to 100 trillion\\noperations per second,\n",
            "         but they are big, thousand-dollar systems\n",
            "  that are spitting out 50\\nto 100 watts of power.\n",
            "                    - [Derek] Obviously this isn't\n",
            "          like an apples apples comparison, right?\n",
            "                  - No, it's not apples to apples.\n",
            "                I mean, training those algorithms,\n",
            "                  you need big hardware like this.\n",
            "   You can just do all sorts\\nof stuff on the GPU,\n",
            "   but if you specifically\\nare doing AI workloads\n",
            "and you wanna deploy 'em,\\nyou could use this i...\n",
            "         You can imagine them in security cameras,\n",
            "                               autonomous systems,\n",
            "           inspection equipment for manufacturing.\n",
            "            Every time they make a Frito-Lay chip,\n",
            "                    they inspect it with a camera,\n",
            "and the bad Fritos get blown\\noff of the convey...\n",
            "         But they're using artificial intelligence\n",
            "            to spot which Fritos are good and bad.\n",
            "      - Some have proposed\\nusing analog circuitry\n",
            "                           in smart home speakers,\n",
            "solely to listen for the wake\\nword, like Alexa...\n",
            "They would use a lot less\\npower and be able to...\n",
            "and reliably turn on the\\ndigital circuitry of ...\n",
            "But you still have to deal\\nwith the challenges...\n",
            "             - So for one of the popular networks,\n",
            "                       there would be 50 sequences\n",
            "           of matrix multiplies that you're doing.\n",
            "Now, if you did that entirely\\nin the analog do...\n",
            "                by the time it gets to the output,\n",
            "                            it's just so distorted\n",
            "            that you don't have any result at all.\n",
            "         So you convert it from the analog domain,\n",
            "                       back to the digital domain,\n",
            "             send it to the next processing block,\n",
            "and then you convert it into\\nthe analog domain...\n",
            "      And that allows you to\\npreserve the signal.\n",
            "    - You know, when Rosenblatt\\nwas first setting\n",
            "                                up his perceptron,\n",
            "                   he used a digital IBM computer.\n",
            "                              Finding it too slow,\n",
            "                he built a custom analog computer,\n",
            "                  complete with variable resistors\n",
            "                  and little motors to drive them.\n",
            "           Ultimately, his idea of neural networks\n",
            "                           turned out to be right.\n",
            "             Maybe he was right about analog, too.\n",
            "Now, I can't say whether\\nanalog computers will...\n",
            "             off the way digital did last century,\n",
            "              but they do seem to be better suited\n",
            "     to a lot of the tasks\\nthat we want computers\n",
            "                                 to perform today,\n",
            "                       which is a little bit funny\n",
            "               because I always thought of digital\n",
            "    as the optimal way of\\nprocessing information.\n",
            "                Everything from music to pictures,\n",
            "to video has all gone\\ndigital in the last 50 y...\n",
            "                         But maybe in a 100 years,\n",
            "                     we will look back on digital,\n",
            "not not as the end point\\nof information techno...\n",
            "                          but as a starting point.\n",
            "                            Our brains are digital\n",
            "     in that a neuron either\\nfires or it doesn't,\n",
            "                           but they're also analog\n",
            "in that thinking takes place\\neverywhere, all a...\n",
            "                             So maybe what we need\n",
            "          to achieve true artificial intelligence,\n",
            "machines that think like\\nus, is the power of a...\n",
            "                                    (gentle music)\n",
            "    Hey, I learned a lot\\nwhile making this video,\n",
            "much of it by playing with\\nan actual analog co...\n",
            "          You know, trying things out for yourself\n",
            "                  is really the best way to learn,\n",
            "and you can do that with this\\nvideo sponsor, B...\n",
            "                    Brilliant is a website and app\n",
            "                     that gets you thinking deeply\n",
            "               by engaging you in problem-solving.\n",
            "     They have a great course\\non neural networks,\n",
            "    where you can test how\\nit works for yourself.\n",
            "               It gives you an excellent intuition\n",
            "about how neural networks can\\nrecognize number...\n",
            "and it also allows you to\\nexperience the impor...\n",
            "           of good training data and hidden layers\n",
            "              to understand why more sophisticated\n",
            "                      neural networks work better.\n",
            "                       What I love about Brilliant\n",
            "             is it tests your knowledge as you go.\n",
            "               The lessons are highly interactive,\n",
            "  and they get progressively\\nharder as you go on.\n",
            "And if you get stuck, there\\nare always helpful...\n",
            "                        For viewers of this video,\n",
            "        Brilliant is offering the first 200 people\n",
            "           20% off an annual premium subscription.\n",
            "              Just go to brilliant.org/veritasium.\n",
            "    I will put that link\\ndown in the description.\n",
            "So I wanna thank Brilliant\\nfor supporting Veri...\n",
            "               and I wanna thank you for watching.\n"
          ]
        }
      ],
      "source": [
        "#Convert column to string\n",
        "text_str = text.to_string(index=False)\n",
        "# text_str.strip()\n",
        "\n",
        "print(text_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open ('text.txt', 'w') as f:\n",
        "    f.write(text_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjadzWsd-5X6"
      },
      "source": [
        "*italicized text*\n",
        "\n",
        "* style-scope ytd-engagement-panel-section-list-renderer (Largest Container of Transcript)\n",
        "* style-scope ytd-transcript-renderer (Smallest Container before individual lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMHd_KbI9z9_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN5L4c2y9rB2UXqw/pNSkMg",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "TM_Neurotic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
